{
  "key": "xpathgenie_design",
  "origin": "https://github.com/goodsun/XPathGenie",
  "title": "XPathGenie — Design",
  "date": "",
  "body": "# XPathGenie — Design Document\n\n> **\"Rub the lamp, get the XPath.\"**\n\n## Overview\n\nXPathGenie is a web application that auto-generates XPath mappings from URLs using AI. The AI is invoked **once per site** (at mapping generation time); subsequent data extraction uses pure DOM operations with no AI cost.\n\n## Problem Statement\n\n- Manual XPath discovery for web scraping is time-consuming (~5-6 hours per site)\n- Label variations across sites (\"お給料\", \"給与\", \"報酬\") require semantic understanding\n- Single-page testing is unreliable; cross-page validation is needed\n- Non-engineers need accessible tooling\n\n## 3-Tool Architecture: G-A-J\n\n```\n┌─────────────┐    localStorage    ┌─────────────┐    localStorage    ┌─────────────┐\n│   Jasmine    │ ──────────────→  │    Genie     │ ──────────────→  │   Aladdin    │\n│  (Join)      │                   │  (Generate)  │                   │  (Analyze)   │\n│              │                   │              │                   │              │\n│ Section      │                   │ AI-powered   │                   │ Cross-page   │\n│ selector     │                   │ XPath gen    │                   │ validation   │\n│ with preview │                   │ + Refine     │                   │ + editing    │\n└─────────────┘                   └─────────────┘                   └─────────────┘\n  jasmine.html                      index.html                       aladdin.html\n```\n\n**Cross-tool communication:** All three tools share state via `localStorage`, enabling seamless handoffs (e.g., \"Open in Aladdin\" button passes URLs + mappings automatically).\n\n### Jasmine — Pre-Analysis Section Selector\n- Interactive preview of fetched pages\n- Click to select main content (include) and noise sections (exclude)\n- Client-side HTML extraction before sending to API\n- i18n support (Japanese/English)\n\n### Genie — XPath Mapping Generator\n- Two modes: Auto Discover and Want List\n- Compresses HTML → sends to Gemini → validates XPaths → auto-refines\n- Core pipeline: Fetch → Compress → Analyze → Validate → Refine\n\n### Aladdin — Cross-Page Validator\n- Tests XPaths against up to 10 URLs simultaneously\n- Tab-based per-page result comparison\n- Real-time XPath editing with instant re-evaluation\n- Export to JSON/YAML\n\n## Directory Structure\n\n```\nXPathGenie/\n├── app.py                  # Flask API server (routes + orchestration)\n├── index.html              # Genie frontend (Vue 3 CDN)\n├── aladdin.html            # Aladdin frontend\n├── jasmine.html            # Jasmine frontend (i18n)\n├── requirements.txt\n├── genie/                  # Backend modules\n│   ├── __init__.py\n│   ├── fetcher.py          # HTML fetcher (SSRF protection, encoding detection)\n│   ├── compressor.py       # HTML structural compression (lxml)\n│   ├── analyzer.py         # Gemini API integration + Refine\n│   └── validator.py        # XPath validation, multi-match detection, narrowing\n├── templates/\n│   └── index.html          # Flask root route template\n├── static/\n│   ├── css/\n│   ├── js/\n│   └── images/\n├── wallpapers/             # Wallpaper gallery page\n│   ├── index.html\n│   └── images/\n├── scripts/                # Evaluation & experiment scripts\n│   ├── evaluate_site.py\n│   ├── experiment1_reproducibility.py\n│   ├── experiment2_ablation.py\n│   └── ...\n├── docs/\n│   ├── DESIGN.md           # This document\n│   ├── whitepaper.md       # Technical whitepaper\n│   ├── ISSUES.md\n│   ├── evaluation/         # Experiment reports & results\n│   └── proposals/          # Design proposals\n├── README.md\n└── LICENSE\n```\n\n## Tech Stack\n\n| Component | Technology |\n|-----------|-----------|\n| Backend | Python / Flask |\n| Frontend | Vue 3 (CDN) / Vanilla CSS |\n| AI | Gemini 2.5 Flash |\n| HTML Parsing | **lxml** (fromstring, etree, tostring) |\n| XPath Execution | lxml |\n| Theme | Dark theme + glassmorphism |\n\n## Pipeline Detail\n\n### 1. fetcher.py — HTML Retrieval\n\n- **Input:** URL array (2-10)\n- **SSRF protection:** Blocks private IPs (10.x, 172.16.x, 192.168.x, 127.x, link-local, IPv6 private)\n- **Encoding detection:** HTTP header → HTML meta charset → fallback chain (utf-8, shift_jis, euc-jp, cp932)\n- **Parallel fetching:** ThreadPoolExecutor, max 5 workers\n- **Limits:** 10MB response size, 15s timeout\n- **Cleanup:** Strips XML declarations and DOCTYPE to prevent lxml parser issues\n\n### 2. compressor.py — Structural Compression\n\nReduces full HTML pages (often 500KB+) to a few KB for AI analysis.\n\n**Process:**\n1. Parse with `lxml.html.fromstring()`\n2. Remove `<script>`, `<style>`, `<noscript>`, `<iframe>`, `<svg>`, `<link>`, `<meta>`, `<head>`\n3. Strip `<header>`, `<footer>`, `<nav>`, `<aside>`\n4. Remove noise sections matching `NOISE_PATTERNS` regex (recommend, sidebar, widget, breadcrumb, modal, footer, banner, ad, popup, cookie, privacy, contact, sns, share, entry, apply, registration)\n5. Find main content section via `_find_main_section()`:\n   - Try `<main>` → `<article>` → structured data section (th/td, dt/dd density) → largest div\n   - Score candidates by text content, excluding noise-pattern matches\n6. `_find_structured_section()`: Finds nearest common ancestor of th/dt elements, merges multiple sections if no dominant one\n7. Truncate text nodes to 30 chars\n8. Remove empty elements\n9. Collapse whitespace\n\n### 3. analyzer.py — AI Analysis\n\n- **Model:** Gemini 2.5 Flash (`gemini-2.5-flash`)\n- **Two prompts:** `PROMPT_DISCOVER` (auto) and `PROMPT_WANTLIST` (targeted)\n- **Output:** JSON `{field_name: xpath_expression}`\n- **Auto-prefixing:** Detects root container class from compressed HTML, scopes all XPaths under it\n- **Wantlist sanitization:** Keys limited to alphanumeric+underscore (50 chars), values truncated to 200 chars\n- **Response parsing:** Handles markdown code blocks, truncated JSON, null values\n\n### 4. validator.py — Validation\n\n- Executes each XPath against all fetched pages using lxml\n- **Content scoring:** Ranks multiple matches by structural context:\n  - `+20` for `<main>`/`<article>` ancestors\n  - `-20` for `<aside>`/`<nav>`/`<footer>` ancestors\n  - `+10`/`-10` for class-based signals (detail, content, sidebar, recommend, etc.)\n  - `+depth` (deeper = more specific = preferred)\n- Calculates confidence = pages_with_hits / total_pages\n- Flags optional fields (confidence < 1.0)\n- Warns on multi-match fields\n\n### 5. Refine Pipeline\n\nWhen XPaths match multiple nodes on a page:\n\n```\nvalidate() → find_multi_matches() → narrow_by_first_match() → refine() → re-validate()\n```\n\n#### find_multi_matches()\n- Detects fields where `doc.xpath()` returns >1 node on any page\n- Collects surrounding HTML snippets (parent chain, up to 4 matches) as context\n- Tracks `all_identical` flag: whether all matched values across all pages are the same\n\n#### narrow_by_first_match() — Mechanical Narrowing (AI cost: 0)\n- For `all_identical=True` fields only\n- Splits XPath into `container // core` parts\n- Walks ancestor chain of each matched element looking for class-bearing ancestors\n- Tests candidate XPaths with intermediate class insertion until exactly 1 match\n- Example: `//container//core` → `//container//div[contains(@class,'detail-body')]//core`\n\n#### refine() — AI Refinement\n- For fields with different values across matches\n- Sends surrounding HTML context to Gemini with `PROMPT_REFINE`\n- AI determines which match is \"primary\" and returns more specific XPath\n\n## Error Handling\n\nThe API uses structured error responses:\n\n```json\n{\n  \"status\": \"error\",\n  \"reason\": \"fetch_failed | access_denied | timeout | compression_empty | analysis_failed | no_fields_detected\",\n  \"message\": \"Human-readable error description\",\n  \"suggestion\": \"Actionable advice for the user\",\n  \"diagnostics\": {\n    \"compressed_size_bytes\": 0,\n    \"encoding_warning\": \"...\",\n    \"compression_warning\": \"...\"\n  }\n}\n```\n\n**Error reasons:**\n| Reason | Trigger | HTTP Status |\n|--------|---------|-------------|\n| `fetch_failed` | All URLs failed to fetch | 400 |\n| `access_denied` | 403 from target site | 400 |\n| `timeout` | Fetch timeout | 400 |\n| `compression_empty` | Compressed HTML is empty (likely SPA) | 422 |\n| `analysis_failed` | Gemini API error | 500 |\n| `no_fields_detected` | AI returned 0 fields | 200 |\n\n## Security\n\n- **SSRF protection:** Private IP blocking in fetcher.py\n- **Rate limiting:** 30 requests/minute per IP (`_check_rate_limit()`)\n- **Origin checking:** Referer/Origin header validation against `ALLOWED_ORIGINS` whitelist\n- **API key isolation:** Gemini key stored server-side only\n- **Wantlist sanitization:** Prevents prompt injection via field names/values\n\n## API Endpoints\n\n### POST /api/analyze\nMain analysis endpoint. Accepts `{urls, wantlist?}`, returns validated XPath mappings with confidence scores.\n\n### GET /api/fetch?url=...\nServer-side HTML fetch for Aladdin (CORS bypass). Returns `{html, url}`.\n\n### GET /\nServes the Genie frontend (`templates/index.html`).\n\n## Future Extensions\n\n- SPA support (Playwright integration for JS-rendered pages)\n- Listing page analysis (pagination structure detection)\n- Mapping history / version management\n- Automated structure change detection\n- Unified cross-site schema mapping",
  "tags": "XPathGenie, Design, bon-soleil, product"
}