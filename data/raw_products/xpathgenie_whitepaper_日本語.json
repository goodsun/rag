{
  "key": "xpathgenie_whitepaper_日本語",
  "origin": "https://github.com/goodsun/XPathGenie",
  "title": "XPathGenie — Whitepaper (日本語)",
  "date": "",
  "body": "# XPathGenie: LLM駆動による自動XPath生成——マルチページ検証と二段階精緻化\n\n## Abstract\n\n本稿では、生のURLからXPathマッピングの生成を自動化するシステムXPathGenieを提案する。本システムは、HTMLの構造的圧縮（約97%削減）、LLMに基づく推論、マルチページ検証、および二段階精緻化を組み合わせて構成される。ページ単位でLLMを呼び出す抽出システムとは異なり、XPathGenieはAIを一度だけ呼び出して再利用可能なXPath式を生成するため、ページあたりの追加AI費用はゼロである。23の医療系求人サイトを対象とした評価では、フィールド単位のヒット率85.1〜87.3%を達成した。本評価は意味的正確性ではなく構造的抽出の安定性（XPathが一貫して非空値を返すか否か）を測定するものであり、これは本システムの目的が値抽出のベンチマークではなく再利用可能なXPath生成にあるためである。23サイト中11サイトでヒット率100%を達成した。さらに、医療以外の5ドメイン（EC、不動産、レシピ、レストランレビュー、ニュース）にわたる10サイトを対象とした補足的なクロスドメイン評価では、マクロ平均ヒット率79.4%を達成し、ドメイン汎化性を確認した。加えて、10ドメイン・10サイト（各3ページ）を対象とした英語サイト評価では、成功サイト（7/10）においてマクロ平均ヒット率78.7%を達成し、GitHubおよびQuotes to Scrapeでは100%に達したことから、言語横断的な適用可能性に関する予備的知見が得られた。コアフィールド分析の結果、スキーマ誘導型抽出はオープンエンド型発見と比較してカバレッジを主に拡大する効果（+13.1pp）を持つことが示された。SWDEベンチマークのサブセット（22サイト、8バーティカル、220ページ）に対するゼロショット評価では、XPathが正常に生成されたフィールドにおいてF1 = 0.689を達成し、検出フィールドの60%が完全一致のF1 = 1.0であった。SWDEの400フィールド-値ペアに対する自動意味分類では意味的精度78.0%を示し、本番サイトでの手動評価による95.0%を補完する結果となった。主要なボトルネックは抽出精度ではなくフィールド発見カバレッジ（46%）にあり、この点はラベル付き訓練データを活用する教師ありシステムAXE（F1 88.1%）とは対照的である。また、圧縮後HTMLと生HTMLにおける空白文字の不一致に起因する**圧縮-生成ギャップ**を特定し、`normalize-space()`述語による解決策を提示する。\n\n## 1. Introduction\n\nWebサイトからの構造化データ抽出は、競合情報分析、求人情報集約、価格監視をはじめとする多様なデータ駆動型アプリケーションの基盤技術である。大半の抽出パイプラインの中核にはXPath——HTML/XML文書からノードを選択するためのクエリ言語——が位置している。その高い表現力にもかかわらず、XPathの記述は依然として手作業に大きく依存している。\n\nこの領域の課題は三つに集約される。第一に**時間的コスト**である。単一のWebサイトに対して信頼性の高いXPathマッピングを構築するには、ページの精査、式の記述、エッジケースへの対応、およびクロスページ検証を含め、通常数時間の専門的作業を要する。数十のターゲットサイトを管理する組織にとっては、数百時間の専門労働に相当する。第二に**暗黙知への依存**である。実効的なXPath構築には、一般的なHTMLパターン（定義リスト、テーブルレイアウト、ネストされたコンテナ）、サイト固有の特異性、および本文コンテンツとサイドバーやレコメンドウィジェット等の周辺要素との区別に関する理解が必要であるが、この知識を体系化することは困難である。第三に**スケーラビリティ**である。ターゲットサイトのHTML構造が変更されるたびに既存のXPathは無効となり、ポートフォリオ規模に比例して線形にスケールする継続的な保守が必要となる。\n\n本研究は人間の判断を排除することを目的とするものではなく、それを自動化パイプライン内における限定的かつ構造化された介入として再配置することを目指す。XPathGenieは、構造的に圧縮されたHTML上で動作するLLM推論問題としてXPath生成を再定式化し、決定論的な検証および精緻化段階で補強することにより、上記の課題に対処する。中核的な設計思想は、AIの呼び出しを初期マッピング発見のただ一度に限定し、以降のすべての処理（検証、機械的精緻化、継続的抽出）を追加AI費用ゼロのDOM操作のみで実行するという点にある。本評価では、正解ラベルに対する意味的正確性ではなく、構造的抽出の安定性（XPathがページ間で一貫して非空値を返すか否か）を測定する。本番環境への導入に際しては、補助ツールAladdinを用いた人手による検証を推奨する。\n\n本論文の主要な貢献は以下の三点である。\n\n1. **限界費用ゼロのXPath生成パイプライン**：HTMLの構造的圧縮（約97%のトークン削減）、LLMに基づく推論、マルチページ検証、および二段階精緻化（AI費用ゼロの機械的絞り込み＋真に曖昧なケースに限定したAI再推論）を統合する。AIの呼び出しはサイトあたり一度であり、以降の抽出はすべて決定論的に行われる。\n2. **エスカレーション型Human-in-the-Loopアーキテクチャ**（Genie–Jasmine–Aladdin）：AIと人間の認知的負荷を適切に分配する。自動生成が87%のサイトを処理し、対話型ツールJasmineが残りの13%に対するワンクリックのエスカレーションパスを提供し、Aladdinが一括検証を可能とする。\n3. **2言語・15以上のドメイン・3つの評価パラダイムにまたがる62サイト規模の多面的評価**：構造的安定性（23本番サイトでヒット率85〜87%）、意味的精度（手動判定100サンプルで95.0%）、および正解ラベルに対するF1（SWDEベンチマーク22サイトでのゼロショット設定で0.689）を報告し、実用的信頼性と教師ありベースラインとの比較可能性の双方を確立する。\n\nさらに、**圧縮-生成ギャップ**——空白文字が正規化された圧縮HTMLと生HTMLの実行コンテキスト間の体系的な不一致——を特定し、`normalize-space()`述語によるその解決策を示す。\n\n## 2. Related Work\n\nWebデータの自動抽出は広範に研究されており、複数のアプローチ群が提案されている。本節では、先行研究を五つのカテゴリに整理して概観する。\n\n### 2.1 ビジュアルスクレイピングおよびCSSセレクタツール\n\n**ビジュアルスクレイピングツール**（Octoparse、ParseHub、Import.io等）は、ユーザが要素を視覚的に選択するポイント・アンド・クリック型のインターフェースを提供する。XPath構文の知識を必要としない点で敷居は低いが、フィールドごと・サイトごとに手動での要素選択が必要であり、マッピング発見そのものの自動化には寄与しない。**CSSセレクタ生成ツール**（SelectorGadget、ブラウザDevTools等）はクリックされた要素に対してセレクタを自動的に提案するが、単一要素・単一ページ上で動作するものであり、クロスページ汎化やバッチ的フィールド発見の機能を欠いている。\n\n### 2.2 ラッパー帰納\n\nラッパー帰納システムは、ラベル付き事例から抽出ルールを学習する。Kushmerick et al. (1997) およびDalvi et al. (2011) の初期の研究は、アノテーション済みページ集合から抽出パターンを学習するパラダイムを確立した。近年では、**Diffbot** (Tong, 2014) や**Zyte Automatic Extraction**（旧AutoExtract）などの商用システムが、明示的なルール記述なしにWebページから構造化データを抽出するために機械学習を適用している。これらのシステムは一般的なページ類型（記事、商品ページ等）において高い性能を発揮するが、特定バーティカル向けに事前学習されたモデルに依存しており、ニッチまたは非定型的なレイアウトに対しては精度が低下する可能性がある。\n\n### 2.3 HTML対応言語モデル\n\nHTML/DOM構造の理解に特化した言語モデル群が開発されている。**MarkupLM** (Li et al., 2022) は、XPathに基づく位置埋め込みを事前学習済み言語モデルに導入し、Webページ分類や半構造化文書からの情報抽出などのタスクを可能とした。**WebFormer** (Wang et al., 2022) は、HTMLトークンとDOM構造の関係をモデル化するTransformerアーキテクチャを提案し、Webページ理解に応用した。**DOM-LM** (Deng et al., 2022) は、構造を考慮した目的関数によりDOM木上で事前学習を行う。これらのモデルは、HTML構造を明示的に符号化することで下流の抽出タスクが改善されることを示しているが、ターゲットスキーマごとにラベル付きデータを用いたファインチューニングを必要とするのが一般的である。\n\n### 2.4 LLMに基づくWeb抽出\n\n大規模言語モデルの登場により、Webデータ抽出に対する新たなアプローチが可能となった。**ScrapeGraphAI** (Perini et al., 2024) は、グラフベースのパイプラインを介してLLM呼び出しを制御し、複数のLLMバックエンドをサポートしつつWebページから構造化データを抽出する。しかし、ScrapeGraphAIは抽出時にページごとにLLMを呼び出すため、AI費用は処理ページ数に比例して線形に増加する。これに対し、XPathGenieはLLMを再利用可能なXPath式の生成のみに使用するため、AI費用はサイトマッピングあたり一度のみ発生する。\n\n**ゼロショット抽出**アプローチは、タスク固有の訓練なしに構造化データを抽出するためにLLMを適用する。Lockard et al. (2020) は、半構造化Webページからのゼロショット閉鎖型情報抽出（ZeroShotCeres）を実証した。より近年の研究では、所望のフィールドの自然言語記述からCSSセレクタやXPath式をLLMに生成させるアプローチが探索されている (Gur et al., 2023; Zhou et al., 2024) が、これらは通常、クロスページ検証を伴わない単一ページ上での動作に留まっている。\n\n**FireCrawl** (2024) や**crawl4ai** (2024) などのオープンソースクローリングフレームワークは、WebページをLLMに適した形式（Markdown、構造化テキスト）に変換し、下流の抽出に供する。これらのツールはコンテンツ変換に主眼を置いており、再利用可能なセレクタの生成は行わず、抽出時にページごとにLLMを呼び出す。\n\nさらに近年では、LLM駆動のXPath生成を明示的に対象とする複数のシステムが提案されている。**XPath Agent** (arXiv:2502.15688, 2024) は、軽量LLMが候補要素を抽出し、より高性能なLLMが複数のサンプルページと自然言語クエリからXPath式を構築する二段階アプローチを採用する。**バーティカルWebサイト向け自動XPath生成** (Huang & Song, 2025, *Journal of King Saud University*) は、XPath生成をマルチタスクの部分問題に分解し、シードページからバーティカルドメイン向けの頑健な式を学習する。**AXE (Adaptive X-Path Extractor)** (arXiv:2602.01838, 2026) は、97.9%のトークン削減を達成する積極的なDOM枝刈りを適用し、0.6Bパラメータのモデルでトレーサブルな抽出のためのGrounded XPath Resolution (GXR) を用いてSWDEベンチマーク上でF1 88.1%を達成した。これらのシステムはXPathGenieに最も近い関連研究であり、主要な差異についてはSection 2.6で議論する。\n\n### 2.5 ボイラープレート検出およびコンテンツ抽出\n\nWebページからのコンテンツ抽出には長い研究の歴史がある。Kohlschütter et al. (2010) は、浅いテキスト特徴量を用いたボイラープレート検出を提案し、本文コンテンツと周辺要素の効果的な分離を実現した。XPathGenieのHTML圧縮パイプライン（Section 3.1）は同様の直観——非コンテンツ要素を特定・除去する——に基づいているが、XPath構築に必要な階層構造を保持するためにDOM構造レベルで操作する点が異なる。\n\n### 2.6 本システムの位置付け\n\nXPathGenieは、先行するすべてのアプローチと決定的なアーキテクチャ上の判断において異なる。すなわち、LLMが生成するのは抽出されたデータではなく、*再利用可能なXPath式*である。これにより、AI費用はマッピング生成時に一度だけ発生し、以降のすべての抽出は純粋なDOMクエリとして——決定論的、高速、かつ無料で——実行される。HTML圧縮パイプラインは、実用的なトークン予算内でのLLM分析を可能にすることで、本アプローチをさらに差別化している。ファインチューニングを必要とするHTML対応言語モデルとは異なり、XPathGenieは慎重に設計されたプロンプトにより汎用LLMを活用する。ラッパー帰納とは異なり、ラベル付き訓練データは不要であり、少数のサンプルURLのみを必要とする。\n\n最新のLLMベースXPathシステムとの比較において、XPathGenieの主要な差異は以下の通りである。(1) **生成後のAI費用ゼロ**——XPath AgentやAXEは抽出時またはエージェント実行時にLLMを呼び出す可能性があるが、XPathGenieの出力は純粋に決定論的な`lxml.xpath()`呼び出しである。(2) **二段階精緻化を伴うマルチページ交差検証**——機械的絞り込みが同一値の多重マッチをゼロコストで解決し、AI再推論は真に曖昧なケースにのみ適用される。このメカニズムは先行システムには見られない。(3) **異なる評価パラダイム**——AXEはSWDEベンチマーク上で正解ラベルに対しF1 88.1%を報告する教師あり設定で動作するのに対し、XPathGenieはラベル付き訓練データを用いないゼロショット設定で動作する。SWDEに対する直接評価（Section 4.14）では、XPathGenieは正常に検出されたフィールドにおいてF1 = 0.689（未検出フィールドを含む厳密F1 = 0.317）を達成しており、その差は主に抽出精度ではなくフィールド発見カバレッジに起因する。(4) **構造保持型圧縮**——AXEの積極的なノード枝刈りとは異なり、XPathGenieの圧縮はXPath構築に必要なDOM階層を保持し、CSSフレームワークとの互換性を犠牲にして構造的忠実性を優先する。\n\n## 3. システムアーキテクチャ\n\nXPathGenieは、URL入力から検証済みXPathマッピングの生成までを6段階のパイプラインとして実装しており、さらに補助ツールAladdinによるヒューマン・イン・ザ・ループ（Human-in-the-Loop）検証を任意で行うことができる。\n\n```mermaid\ngraph TD\n    A[\"URL Input (2–10 URLs)\"] --> B[\"HTML Fetcher<br/>SSRF-protected\"]\n    B --> C[\"HTML Compressor<br/>695 KB → 20 KB (97% reduction)\"]\n    C --> D[\"LLM Analyzer<br/>Gemini 2.5 Flash<br/>Single inference call\"]\n    D --> E[\"Multi-page Validator<br/>Confidence scoring\"]\n    E --> F{\"Multi-match<br/>detected?\"}\n    F -- \"Identical values\" --> G[\"Mechanical Narrowing<br/>Ancestor class insertion<br/>Zero AI cost\"]\n    F -- \"Different values\" --> H[\"AI Refinement<br/>Contextual re-inference\"]\n    F -- \"No\" --> I[\"Final Mappings\"]\n    G --> J[\"Re-validate\"]\n    H --> J\n    J --> I\n    I --> K[\"Open in Aladdin\"]\n    K --> L[\"10-page Bulk Verification\"]\n    L --> M[\"Manual XPath Editing<br/>+ Real-time Re-evaluation\"]\n    M --> N[\"Export: JSON / YAML\"]\n\n    style A fill:#7c5cfc,color:#fff\n    style D fill:#9f7aea,color:#fff\n    style G fill:#4caf50,color:#fff\n    style H fill:#ff9800,color:#fff\n    style K fill:#7c5cfc,color:#fff\n    style N fill:#4caf50,color:#fff\n```\n\n### 3.1 HTML圧縮\n\n現代のウェブサイトにおける生のHTMLページは500 KBを超えることが常であり、複数ページを同時に分析する場合にはLLMの実用的なコンテキストウィンドウを大幅に超過する。圧縮モジュール（`genie/compressor.py`）は、多段階の構造的削減を適用する。\n\n1. **タグ除去**: 抽出可能なコンテンツを持たない要素を完全に除去する。対象は`script`、`style`、`noscript`、`iframe`、`svg`、`link`、`meta`、`head`である。\n\n2. **構造的除去**: レイアウト専用のコンテナ要素（`header`、`footer`、`nav`、`aside`）を除去する。これらの要素には対象となるデータフィールドが含まれることはまれである。\n\n3. **ノイズの事前除去**: メインセクション検出に先立ち、ノイズパターンに合致するすべてのサブツリーをドキュメントから除去する。これにより、非コンテンツ領域（例：`<th>`/`<dt>`要素を含むプライバシーポリシーセクション）がメインセクション検出アルゴリズムに悪影響を及ぼすことを防止する。ノイズパターンは、class属性またはID属性を以下の正規表現に対して照合する: `recommend|related|sidebar|widget|breadcrumb|modal|slide|footer|banner|ad[-_]|popup|cookie|privacy|policy|inquiry|contact|sns[-_]|share`。\n\n4. **メインセクション検出**: 本アルゴリズムは、3段階のフォールバック機構を通じて主要コンテンツ領域を特定する。(a) 明示的なセマンティック要素（`<main>`、`<article>`）、(b) **構造化データ検出**——構造化マーカー数（`<th>`および`<dt>`子孫要素の個数）とテキストコンテンツ長の積により候補コンテナをスコアリングする方式であり、小規模なサマリーセクションを回避しつつデータリッチな領域を高精度に識別する、(c) 最大テキスト量を持つ`<div>`または`<section>`。単一のコンテナが支配的でない場合（すなわち、最上位候補のスコアが全スコアの50%未満の場合）、条件を満たす複数のセクションを仮想ラッパー要素に統合する。`<body>`要素は過度に広範な選択を防ぐため候補から明示的に除外される。この多信号スコアリング方式は、単純なマーカー数のカウントでは大規模なコンテンツ領域よりも小規模な「チェックポイント」セクションが選択される場合があるという評価結果を踏まえて改良されたものである。\n\n5. **残留ノイズ除去**: 特定されたメインセクション内において、ノイズパターンに合致する残存子サブツリーを再帰的に除去する。\n\n6. **テキスト切り詰め**: すべてのテキストノードを30文字に切り詰める。これにより、構造的ラベル（例：`給与`、`勤務地`）を保持しつつ、XPath生成に寄与しない冗長なコンテンツによるトークン消費を抑制する。\n\n7. **空要素の刈り込み**: テキストコンテンツも子要素も持たない要素を除去する（`br`、`hr`、`img`、`input`等の自己閉鎖タグを除く）。\n\n8. **空白の正規化**: 冗長な空白を縮約し、タグ間の空白を除去する。\n\n以上の処理により、DOM階層構造、class名、およびXPath構築に不可欠なラベルテキストを保持した構造的骨格が得られ、約97%のサイズ削減（例：695 KB → 20 KB）を達成する。各圧縮ページはLLMへの送信前にさらに8,000文字を上限として切り詰められる。\n\n```mermaid\ngraph TD\n    Raw[\"Raw HTML<br/>&gt;500 KB\"] --> A[\"1. Tag Removal<br/>script / style / svg / head\"]\n    A --> B[\"2. Structural Strip<br/>header / footer / nav / aside\"]\n    B --> C[\"3. Noise Pre-removal<br/>sidebar / widget / recommend / ad\"]\n    C --> D[\"4. Main Section Detection<br/>main → structured-data scoring → largest div\"]\n    D --> E[\"5. Residual Noise Removal\"]\n    E --> F[\"6. Text Truncation<br/>30 chars per node\"]\n    F --> G[\"7. Empty Element Pruning\"]\n    G --> H[\"8. Whitespace Normalization\"]\n    H --> Out[\"Compressed HTML<br/>~20 KB (97% reduction)\"]\n\n    style Raw fill:#e53e3e,color:#fff\n    style Out fill:#4caf50,color:#fff\n    style D fill:#7c5cfc,color:#fff\n```\n\n### 3.2 LLMによるXPath生成\n\n本システムは2種類の推論モードを提供しており、いずれもGemini 2.5 Flashに対する単一呼び出しプロンプトとして実装されている。ほぼ決定論的な出力を得るために`temperature=0.1`を、構造化レスポンスのために`responseMimeType=application/json`を設定している。\n\n**Auto Discoverモード**は、圧縮されたHTMLサンプルとともに、すべての有意なデータフィールドを識別してフィールド名からXPath式へのJSONマッピングを返すよう指示するプロンプトを送信する。プロンプトには、下流の信頼性確保に不可欠な以下の制約が含まれる。\n\n- XPathは`//`プレフィックスを使用し、要素ノードを選択すること（`text()`ノードではない）\n- class属性のマッチングには`contains(@class, ...)`を使用し、複数classの属性に対応すること\n- テキストマッチングには`normalize-space()`を使用し、圧縮HTMLと生HTMLの間の空白差異に対応すること（例：`//dt[text()='給与']`ではなく`//dt[normalize-space()='給与']`）\n- `contains()`および`normalize-space()`以外のXPath関数は禁止（`substring-after`等は使用不可）\n- 出力は最も重要な20フィールドに限定\n- フィールド名は小文字の英語で意味的に汎用的であること\n\n**Want Listモード**は、キーが希望するフィールド名、値が意図するデータの自然言語記述であるユーザ提供のJSONスキーマを受け付ける。例：`{\"contract\": \"雇用形態 (employment type: 正社員/full-time, 契約社員/contract, パート/part-time, etc.)\"}`。LLMはリテラルなラベルテキストではなく*意味*によってフィールドをマッチングするため、言語を跨いだセマンティックマッチングが可能となる。本モードはAuto Discoverと比較して約30%少ないトークン消費で動作する。\n\nLLMの応答後、システムは**自動ルートプレフィックス付加**を実行する。最初の圧縮HTMLのルート要素に有意なclass名がないか検査し、見つかった場合はスコーピングコンテナとしてすべての生成XPathの先頭に付加する。これにより、XPathが主要コンテンツ領域にアンカリングされることが保証される。\n\n### 3.3 マルチページ検証\n\n生成されたXPathは、取得したすべてのページの元の（非圧縮）HTMLに対して評価される。各フィールドについて、バリデータは以下を算出する。\n\n- **信頼度スコア**: XPathが少なくとも1つの非空結果を返すページの割合。スコア1.0は、分析対象のすべてのページでXPathが機能することを示す。なお、この指標は*抽出カバレッジ*を測定するものであり、ゴールドスタンダードに対する正解照合は行わない。\n- **サンプル値**: 各ページから抽出されたテキストの先頭100文字。人間による迅速な目視確認を可能にする。\n- **複数マッチ警告**: いずれかのページでXPathが複数のDOMノードにマッチしたフィールドは、精緻化の対象としてフラグが立てられる。\n\n単一のXPathが複数ノードにマッチした場合、バリデータは深度重み付きコンテンツスコアリングアルゴリズム（3.5節）を用いて最適なマッチを選択する。\n\n### 3.4 二段階精緻化\n\n求人サイトをはじめとする構造化コンテンツのウェブサイトでは、セクション間でラベルが頻繁に繰り返される。例えば「勤務地」というフィールドが、メインの詳細領域、サイドバーの概要、関連求人ウィジェットに同時に出現することがある。単純な`//dt[normalize-space()='勤務地']/following-sibling::dd[1]`というXPathは、すべての出現箇所にマッチしてしまう。\n\nXPathGenieの精緻化機構は、二段階の戦略によりこの問題に対処する。\n\n**第1段階：機械的絞り込み（AIコストゼロ）。** マッチしたすべての値が同一の場合（例：同一の求人IDが3箇所に出現）、システムは決定論的なDOM解析を実行する。マッチした各要素について祖先チェーンを走査し、class属性を持つ要素を探索する。次に、ルートコンテナとコア式の間に中間コンテナセレクタ（例：`//div[contains(@class,'p-jobDetail-body')]`）を挿入した候補XPathを構築する。正確に1件のマッチを生成する最初の候補が採用される。この処理はLLM呼び出しを必要とせず、計算コストも無視できる程度である。\n\n**`narrow_by_first_match`の設計上の注意:** 機械的絞り込みアルゴリズムは、候補XPathの検証を入力セットの最初のページに対してのみ実行する。これは性能を考慮した意図的なトレードオフであり、すべての候補についてすべてのページを検査することは処理時間の観点から現実的ではない。後続の再検証段階（全ページに対して実行）が、汎化に失敗した絞り込みを検出する。\n\n```\nBefore: //div[contains(@class,'p-offerContainer')]//div[contains(@class,'c-favoriteBtn')]/@data-job_id\n→ 3 matches (identical value)\n\nAfter:  //div[contains(@class,'p-offerContainer')]//div[contains(@class,'p-jobDetail-body')]//div[contains(@class,'c-favoriteBtn')]/@data-job_id\n→ 1 match\n```\n\n**第2段階：AI再推論（文脈的精緻化）。** マッチした値が異なる場合（例：メイン求人の勤務地と推薦求人の勤務地）、機械的絞り込みではどのマッチが正しいか判定できない。この場合、システムは各マッチの周辺HTMLコンテキスト（マッチあたり最大1,500文字、最大4マッチ）を精緻化プロンプトとともにLLMに送信する。プロンプトは、*主要な*マッチ——典型的にはメイン求人詳細セクションの最も詳細なコンテンツ——を識別し、より特異的なXPathを返すようモデルに指示する。\n\n精緻化プロンプトは、有意なclass名を持つ中間的な構造コンテナの探索をLLMに明示的に誘導し、単一マッチの精度を確保しつつ可読性と保守性を維持するXPathの生成を促す。\n\n精緻化後、すべてのマッピングは再検証され、精緻化されたXPathがページ横断的な精度を維持していることを確認する。\n\n```mermaid\ngraph TD\n    V{\"Multi-match<br/>detected?\"}\n    V -- \"No\" --> OK[\"✓ Use XPath as-is\"]\n    V -- \"Yes\" --> Check{\"Values<br/>identical?\"}\n    Check -- \"Yes (e.g., same ID<br/>in 3 places)\" --> T1[\"Tier 1: Mechanical Narrowing<br/>Ancestor class insertion<br/>Zero AI cost\"]\n    Check -- \"No (e.g., main vs.<br/>sidebar location)\" --> T2[\"Tier 2: AI Re-inference<br/>Context-aware refinement<br/>1 LLM call\"]\n    T1 --> RV[\"Re-validate<br/>all pages\"]\n    T2 --> RV\n    RV --> OK\n\n    style OK fill:#4caf50,color:#fff\n    style T1 fill:#7c5cfc,color:#fff\n    style T2 fill:#ff9800,color:#fff\n    style V fill:#90caf9,color:#000\n```\n\n### 3.5 深度重み付きコンテンツスコアリング\n\nXPathが複数ノードにマッチし、サンプル表示のために単一の「最適」値を選択する必要がある場合、バリデータは構造的信号とDOM深度を組み合わせたコンテンツスコアリングアルゴリズムを使用する。\n\n```python\nscore = 0\nfor ancestor in node.ancestors():\n    if ancestor.tag in ('main', 'article'):\n        score += 20\n    elif ancestor.tag in ('aside', 'nav', 'footer'):\n        score -= 20\n    if class/id contains MAIN_SIGNALS ('detail', 'content', 'primary', ...):\n        score += 10\n    if class/id contains SIDE_SIGNALS ('sidebar', 'recommend', 'related', ...):\n        score -= 10\nscore += depth  # deeper nesting = more specific context\n```\n\n深度成分は、典型的なウェブサイトレイアウトにおいて、主要コンテンツ領域はヘッダーのショートカットやサイドバーの概要といった周辺要素よりも深いネスト構造を有するという重要な観察を反映している。タグ名およびclass名からのセマンティック信号と組み合わせることで、このヒューリスティックは重複要素の中からメインコンテンツのインスタンスを高い信頼性で識別する。\n\n### 3.6 人間介入型検証（Aladdin）\n\nXPathGenieはマッピング生成を自動化するが、本番環境への展開においては人間による検証が有益である。補助ツール**XPathAladdin**は以下の機能を提供する。\n\n- **10ページ一括テスト**: 同一サイト種別から最大10件のURLを入力でき、Aladdinがすべてのページを取得して各XPathを各ページに対して評価する。\n- **タブ形式の比較**: 結果はタブインターフェースで提示され、ページごとの抽出値の確認が可能である。\n- **ページ横断ヒット率**: 各フィールドについて、値を返したページ数を表示し、ページ固有の要素を即座に把握できるようにする。\n- **リアルタイムXPath編集**: インターフェース上で直接XPathを修正でき、読み込み済みの全ページに対して即時再評価が行われる。\n- **シームレスな連携**: XPathGenie内の「Open in Aladdin」ボタンにより、localStorageを介してすべてのURLと生成済みマッピングが転送され、手動のデータ入力は不要である。\n- **エクスポート**: 検証済みマッピングをJSONまたはYAML形式でエクスポート可能（teddy_crawler抽出フレームワークと互換）。\n\nこのアーキテクチャは意図的な役割逆転を体現している。従来、人間がXPathを記述しマシンがそれを検証するという分担であったが、XPathGenieのワークフローではマシンがXPathを記述し人間がそれを検証する。\n\n### 3.7 インタラクティブセクション選択（Jasmine）\n\nノイズパターンシステム（3.1節）は無関係なコンテンツの一般的なケースに対処するが、圧縮と生成の間のギャップは本質的に*選択問題*として残る。すなわち、LLMにページのどの部分を提示すべきかという問題である。ルールベースのアプローチには本質的な限界があり、あらゆるサイトの構造的特異性を事前に想定することはできない。補助ツール**XPath Jasmine**は、インタラクティブなユーザ主導のセクション選択を通じてこのギャップに対処する。\n\n#### 3.7.1 課題：ルールベース抽象化の限界\n\nHTML圧縮器のノイズパターン機構（ナビゲーション、フッター、サイドバー、フォームの除去）は、人間の「選択的注意」——複雑なページを見て瞬時に関連するデータテーブルに注目し、それ以外を無視する能力——の再現を試みるものである。しかし、人間の抽象化は意味的理解に基づいて機能するのに対し、ルールベースのパターンマッチングは構文的手がかり（class名、タグ構造）に基づいて動作する。これらの手がかりが欠如している、あるいは誤解を招くものである場合、圧縮器は誤ったコンテンツセクションを選択してしまう。\n\n具体例として、yakuzaishisyusyoku.netでは応募フォーム（`div.entry_box`）が実際の求人詳細テーブルよりも多くの`<th>`/`<td>`ペアを含むテーブルを有していた。圧縮器の深度重み付きコンテンツスコアリングは、構造スコアがより高いという理由でフォームを「メインコンテンツ」として選択し、結果として有用なフィールドマッピングはゼロとなった。この修正には新たなノイズパターン（`entry_box|entry_form|apply_|registration`）の追加が必要であったが、これは事後対応に過ぎない。新たな障害モードが発生するたびに新たなルールが必要となるのである。\n\n#### 3.7.2 アプローチ：ブラックアウトプレビュー\n\nJasmineは対象ページをiframe内にレンダリングし、LLMが分析すべきセクションをユーザがインタラクティブに選択できるようにする。\n\n1. **クリックで選択（緑）**: ユーザが任意の要素をクリックして分析対象として選択する。選択された要素は緑色のアウトラインでハイライトされる。\n2. **Shift+クリックで除外（赤）**: 選択されたセクション内で、さらにサブセクションを除外できる（例：求人詳細コンテナ内の埋め込みフォーム）。\n3. **ブラックアウト表示**: 選択セクション*外*のすべてのコンテンツが暗転表示（opacity: 0.15、グレースケール、brightness: 0.3）され、LLMが参照する範囲の即時的な視覚プレビューを提供する。これにより、圧縮の境界が可視化され、直感的に把握可能となる。\n4. **親パスナビゲーション**: CSSセレクタパス（例：`#result > div.detail_box > table`）が表示され、各祖先要素がクリック可能であり、親要素をクリックすることで選択範囲を拡大できる。\n\nこのインタラクションモデルは、圧縮器の最も重要な判断——セクション選択——をユーザに外在化する。ユーザはルールベースシステムが欠く意味的理解を有しており、人間の読者としてページを閲覧し、「ここを分析せよ、ここは無視せよ」と直接指示できる。\n\n#### 3.7.3 エスカレーションモデル\n\nJasmineは自動化と人間の監視のバランスを調整する3つの動作モードをサポートする。\n\n- **auto**: 既存の圧縮器ヒューリスティクスと自動リトライによる完全自動セクション選択。初回分析でフィールド数がゼロの場合、次にスコアの高いセクションを選択してリトライする。バッチ処理/APIワークフローに適する。\n- **confirm**: LLM分析開始前に、圧縮器の選択結果がブラックアウトプレビューとしてユーザに提示され確認を求める。LLMが参照する内容の可視性を求めるインタラクティブ利用に適する。\n- **auto+escalate**: デフォルトは自動モードであるが、失敗時にはインタラクティブプレビューが起動し、ユーザが正しいセクションを手動で選択する。SaaS展開における推奨モードであり、構造が整ったサイトではフリクションを最小化しつつ、エッジケースを優雅に処理する。\n\n#### 3.7.4 パイプライン統合：Generate → Join → Analyze\n\nJasmineはlocalStorageベースの状態共有を通じて既存ツール群と統合され、各ツール名がその機能を反映した3段階パイプラインを構成する。\n\n| ツール | 機能 | 役割 |\n|------|----------|------|\n| **Genie** (Generate) | LLMベースのXPath生成 | 圧縮HTMLからフィールド→XPathマッピングを生成 |\n| **Jasmine** (Join) | インタラクティブセクション選択 | ユーザの意図とページ構造を結合し、Genieが参照する範囲を制御 |\n| **Aladdin** (Analyze) | マルチページ検証 | 複数ページにわたるマッピング品質を分析 |\n\nワークフローは以下のように進行する。\n\n1. **Want List**（localStorageで共有）: ユーザが希望フィールドとサンプル値を定義する（例：`{\"job_title\": \"薬剤師\", \"salary\": \"年収500万円\"}`）。\n2. **Jasmine**: ユーザが対象URLを読み込み、ブラックアウトプレビューで関連セクションを選択し、分析を開始する。JasmineはGenie APIエンドポイントに選択セクション（除外部分を反映済み）を送信する。\n3. **結果表示**: 抽出された値（XPath式ではない）がインラインで表示され、複数マッチ警告はオレンジ色でハイライトされる。内部的なXPathマッピングはlocalStorageに保存される。\n4. **Aladdinへの引き継ぎ**: ワンクリックでAladdinに遷移し、localStorageからURLとマッピングを自動読み込みしてマルチページ検証を実行する。\n\nこのパイプラインは、**人間の最も価値ある貢献はコードを書くことではなく、注意を向けること**であるという原則を体現している。ユーザの唯一のタスクはページの正しい部分を指し示すことであり、それ以外のすべて（圧縮、LLM推論、検証、精緻化）は自動化される。\n\n#### 3.7.5 設計思想：AIを適用すべきでない領域の明確化\n\nJasmineの設計は、AIと人間の認知の境界に関する意図的なアーキテクチャ上の決定を反映している。\n\n- **AIが最適な領域**: HTML構造間のパターン認識、構文的に正確なXPath式の生成、複数ページにわたる体系的な検証。\n- **人間が最適な領域**: ページレイアウトの意味的理解、「求人詳細」と「応募フォーム」の一目での識別、どの情報が関連するかの判断。\n\n圧縮器のノイズパターンは人間的なセマンティック判断をルールにエンコードする試みであるが、これは本質的に*知識表現問題*であり、ルールに合致しない構造を持つサイトは常に存在する。Jasmineはこの限界を認識し、エスケープハッチを提供する。ルールが失敗した場合、人間がワンクリックで介入でき、残りのパイプラインは自動的に進行する。\n\nこの「AIによる生成、人間による選択」という分業は、5.2節で述べるより広範な役割逆転を反映している。人間がXPathを記述するのではなく検証するのと同様に、人間が選択ルールを実装するのではなくコンテンツセクションを選択する。いずれの場合も、人間のタスクは*構築*（XPathの記述、ルールの実装）から*認識*（値の検証、関連コンテンツの認識）へと移行している——これは人間が容易にこなす認知タスクである。\n\n#### 3.7.6 実証的検証\n\nインタラクティブセクション選択の効果を定量化するため、23サイトの評価コーパスにおけるエスカレーション率とヒット率の改善を測定した。\n\n**エスカレーション率。** 自動セクション選択（圧縮器ヒューリスティクスのみ）を使用した場合、23サイト中3サイト（13%）でヒット率が50%を下回り、Jasmineによる人間の介入が必要となるサイトの上限を示した。\n\n| サイト | 自動ヒット率 | 障害モード |\n|------|--------------|-------------|\n| yakuzaishisyusyoku | 0.0%（2フィールド検出、いずれも0%） | 求人詳細テーブルの代わりに応募フォームが選択された |\n| cocofump | 20.0%（1/5フィールド） | 非標準的なdiv/spanレイアウト |\n| phget | 20.0%（1/5フィールド） | 非標準的なdiv/spanレイアウト |\n\n残りの20サイト（87%）は完全自動処理でヒット率66%以上を達成し、人間の介入を必要としなかった。この結果は、auto+escalateモードがフリクションを最小化することを裏付ける。大多数のサイトは自動的に処理され、Jasmineの介入はヒューリスティックによるセクション選択が失敗する約13%のサイトにのみ必要となる。\n\n**ケーススタディ：yakuzaishisyusyoku（0% → 100%）。** このサイトはJasmineの価値を最も明瞭に実証する事例である。自動モードでは、圧縮器の深度重み付きコンテンツスコアリングが、実際の求人詳細テーブル（`div.detail_box`）ではなく応募フォーム（`div.entry_box`）を選択した。フォームの方が多くの`<th>`/`<td>`ペアを含んでいたためである。結果として、検出フィールドはわずか2件で、いずれもヒット率0%であった。\n\nJasmine相当のセクション選択（`div.detail_box`を分析対象として指定）を適用した場合、システムは以下の結果を生成した。\n\n| 条件 | 検出フィールド数 | 平均ヒット率 | 100%達成フィールド数 |\n|-----------|----------------|-------------|-----------------|\n| Auto（ノイズ修正前） | 2 | 0.0% | 0 |\n| Auto（ノイズパターン修正後） | 20 | 95.0% | 18/20 |\n| Jasmine（セレクタ：`div.detail_box`） | 20 | **100.0%** | 20/20 |\n\nノイズパターンの修正（`entry_box|entry_form`の除外ルール追加）により性能の大部分が自動的に回復したが、Jasmineの明示的なセクション選択は完全な結果を達成した。これは、人間のセマンティック判断が利用可能な場合、十分にチューニングされたヒューリスティクスをも凌駕することを確認するものである。\n\n**エスカレーションモデルへの示唆。** 13%のエスカレーション率はauto+escalate設計を検証するものである。100サイトのポートフォリオに対して、約87サイトが完全自動で処理され、約13サイトのみが単一の人間インタラクション（Jasmineのブラックアウトプレビューで正しいコンテンツセクションをクリック）を必要とする。Jasmineインタラクション1回あたり推定30秒として、エスカレーション対象サイトに要する人的作業量は合計約6.5分——残りのサイトの自動処理により節約される時間と比較して無視できる水準である。\n\n#### 3.7.7 セマンティック精度の検証\n\n主要な評価指標であるヒット率は構造的抽出の安定性——XPathが非空の値を返すか否か——を測定するが、意図されたフィールドに対して*正しい*値が抽出されているかどうかは評価しない。この限界に対処するため、23サイトのWant List評価コーパスから抽出されたフィールド-値ペア（非空抽出350件、seed=42でサンプリング）のうち100件のランダムサンプルに対してセマンティック精度評価を実施した。\n\n各ペアは以下の3基準により人手で判定した。\n\n| 判定 | 定義 | 件数 |\n|----------|-----------|-------|\n| ✅ 正解 | 抽出値がフィールド名に対して意味的に適切 | 82 |\n| ⚠️ 部分正解 | 正しい情報を含むが付加的なノイズを伴う（例：資格フィールドに資格名*と*経験要件の両方が同一DOMノードから抽出される） | 13 |\n| ❌ 不正解 | 抽出値がフィールド名に対して不正確 | 5 |\n\n**セマンティック精度（正解＋部分正解）：95.0%。** 厳密精度（正解のみ）：82.0%。\n\n不正解5件は以下の3カテゴリに分類される。\n\n1. **ラベル誤抽出**（1件）：XPathが実際の市区町村名ではなくフィールドラベルテキスト（「勤務地」）を取得した。ラベルと値が同一の親要素を共有する曖昧なDOM構造に起因する。\n2. **隣接セクションからの漏出**（2件）：XPathが隣接セクションのコンテンツを取得した（例：休日フィールドに結合データブロックから給与・賞与情報が含まれる）。\n3. **フィールド混同**（2件）：意味的に類似するフィールド（例：`price_rule`と`welfare_program`）が、サイトが給与と福利厚生の両方に単一コンテナを使用している場合に誤ったコンテンツにマッピングされた。\n\n部分正解13件は主に「正しい値＋ノイズ」パターン（例：`license`フィールドに必要資格名と経験要件の両方が含まれる）を示しており、後処理によるクリーンアップが可能である。\n\nこれらの結果は、XPathGenieの構造的ヒット率（87.3%）が実運用において高いセマンティック精度（95.0%）に転化することを確認するものである。非空抽出の大多数が意図された情報を含んでおり、5%のエラー率は人間の読者にとってもフィールド境界が不明瞭な構造的に曖昧なケースに集中している。これは、残存する誤りがXPath生成の体系的な失敗ではなく、ページ構造の本質的な曖昧性に起因することを示唆している。\n\n**実効精度。** 上記2指標を組み合わせることで、エンドツーエンドのシステム性能をより包括的に把握できる。ヒット率（87.3%）× セマンティック精度（95.0%）= **実効精度82.9%**——これは、あるフィールドがあるページにおいて意味的に正しい抽出結果を返す確率を表す。この統合指標は、構造的抽出の失敗（XPathが空を返す）とセマンティック抽出の誤り（XPathが誤った値を返す）の両方を考慮しており、人間による検証前に下流の利用者が期待できる真の歩留まりを表している。\n\n## 4. 評価\n\n### 4.1 実験設定\n\nXPathGenieの評価は、薬剤師・看護師・介護・一般医療の各領域にまたがる日本の医療・ヘルスケア系求人サイト35件を対象に実施した。35サイトのうち23サイトはSSR（サーバーサイドレンダリング）による詳細ページを持ち、標準的なHTTPリクエストでアクセス可能であった。残りの12サイトは以下の理由により除外した：7サイトはJavaScriptレンダリングが必要（SPA）、3サイトはHTTPエラー（403/500）または認証が必要、2サイトはその他のアクセス上の問題があった。さらに、医療求人領域を超えた汎化性能を検証するため、5つの非医療ドメイン（EC、不動産、レシピ/UGC、飲食店レビュー、ニュース）にまたがる10サイトを対象としたクロスドメイン評価（Section 4.12）、多言語汎化性能を検証するための英語サイト10件・10ドメイン（各3ページ、計30ページ）を対象としたクロスドメイン評価（Section 4.13）、および教師ありベースラインとのF1直接比較を可能にするためのSWDEベンチマーク評価（8バーティカル・22サイト、各10ページ、計220ページ）（Section 4.14）を実施した。\n\n各サイトについて単一の詳細ページURLを用いて解析を行い、生成されたXPathマッピングを同一サイトの10件の詳細ページに対してクロスバリデーションした。本論文で報告する全評価結果は、2026年2月17日にGemini 2.5 Flash（`temperature=0.1`）を用いて実施した単一の実験ランに基づく。各サイト・各モードの生データは`docs/evaluation/results/`にアーカイブされており、ファイル名にはサイト番号・サイト名・評価モードが符号化されている。なお、Auto DiscoverモードとWant Listモードではフィールド数が異なる。これは各モードが異なるフィールドマッピングセットを生成するためである。過去の評価ラン（`EVALUATION_REPORT.md`に記載）は異なる構成を使用しており、以下の表と直接比較すべきではない。\n\n**評価指標。** 本評価では以下の3段階の指標を報告する：\n\n1. **フィールドレベルhit rate**：生成されたXPathが少なくとも1つの非空結果を返すページの割合。これはフィールドごとの抽出カバレッジを測定するものであり、正解アノテーションに対する意味的正確性を測定するものではない。\n2. **サイトレベル平均hit rate**：当該サイトにおけるフィールドレベルhit rateの平均値。\n3. **コアフィールドhit rate**：求人サイトに普遍的に存在する7つの「コアフィールド」（給与、勤務地、雇用形態、職種、施設名、勤務時間、休日）のみを対象として算出したhit rate。この指標は、最も重要なデータが抽出可能であるかという実用的有用性を反映する。\n\n以下の2つの評価条件を検証した：\n\n- **Auto Discoverモード**：スキーマの指定なし。LLMが自律的にフィールドを特定しXPathを生成する。\n- **Want Listモード**：30項目の統一スキーマ定義（例：`\"contract\": \"雇用形態（正社員、契約社員、パート等）\"`、`\"facility_name\": \"勤務先の施設名・会社名\"`）を提供し、LLMの抽出対象を指示する。\n\n### 4.2 結果：Auto Discoverモード\n\n| # | サイト | ドメイン | 構造 | フィールド数 | Perfect | Hit Rate |\n|---|------|--------|-----------|--------|---------|----------|\n| 2 | selva-i | 薬剤師 | dt/dd | 20 | 20/20 | **100.0%** |\n| 4 | yakumatch | 薬剤師 | th/td | 20 | 20/20 | **100.0%** |\n| 9 | oshigoto-lab | 医療 | dt/dd+th/td | 12 | 12/12 | **100.0%** |\n| 12 | bestcareer | 薬剤師 | th/td (Shift-JIS) | 20 | 20/20 | **100.0%** |\n| 13 | pharmapremium | 薬剤師 | th/td | 14 | 14/14 | **100.0%** |\n| 18 | nikken-care | 介護 | dt/dd | 10 | 10/10 | **100.0%** |\n| 19 | nikken-nurse | 看護 | dt/dd | 10 | 10/10 | **100.0%** |\n| 21 | MRT-nurse | 看護 | div/span | 6 | 6/6 | **100.0%** |\n| 24 | kaigo-work | 介護 | th/td | 14 | 14/14 | **100.0%** |\n| 25 | w-medical-9 | 医療 | th/td | 19 | 19/19 | **100.0%** |\n| 26 | firstnavi | 看護 | th/td | 19 | 19/19 | **100.0%** |\n| 5 | mynavi | 薬剤師 | dt/dd | 20 | 19/20 | 98.0% |\n| 16 | pharmalink | 薬剤師 | th/td | 20 | 17/20 | 98.5% |\n| 32 | yakusta | 薬剤師 | dt/dd+th/td | 18 | 17/18 | 98.3% |\n| 31 | ph-10 | 薬剤師 | th/td | 15 | 11/15 | 96.7% |\n| 35 | kaigokango | 介護/看護 | th/td | 18 | 17/18 | 95.6% |\n| 30 | mc-pharma | 薬剤師 | th/td (Shift-JIS) | 15 | 12/15 | 92.7% |\n| 20 | cocofump | 介護 | dt/dd+th/td | 6 | 5/6 | 91.7% |\n| 14 | caresta | 介護 | th/td | 17 | 12/17 | 85.9% |\n| 1 | tsukui-staff | 介護 | dt/dd | 20 | 13/20 | 83.0% |\n| 8 | apuro | 薬剤師 | dt/dd+th/td | 13 | 9/13 | 73.1% |\n| 6 | phget | 薬剤師 | th/td | 9 | 1/9 | 11.1% |\n| 10 | yakuzaishisyusyoku | 薬剤師 | th/td | 15 | 1/15 | 6.7% |\n\n**注：** 全結果は、エンコーディング自動検出（Shift-JIS/EUC-JP）、XML宣言の除去、構造化データを考慮したメインセクション検出、ノイズパターンの拡張（プライバシーポリシー、問い合わせフォーム）、事前ノイズ除去、およびLLMプロンプトにおける`normalize-space()`の採用による空白耐性XPath生成など、一連のシステム改善を適用した後に得られたものである。これらのエンジニアリング上の修正は、正確なHTML処理の前提条件である。\n\n**要約（Auto Discover、23サイト）：** フィールドレベル：350フィールド中298フィールドがperfect（**85.1%**）。11サイトが100%を達成。コアフィールドhit rate：検出されたコアフィールド100件中96件がperfect（**96.0%**）。\n\n### 4.3 結果：Want Listモード（スキーマガイド付き）\n\n23サイト全てについて、30項目の統一求人スキーマを用いたWant Listモードで評価を実施した。\n\n| # | サイト | ドメイン | フィールド数 | Perfect | Hit Rate |\n|---|------|--------|--------|---------|----------|\n| 2 | selva-i | 薬剤師 | 23 | 23/23 | **100.0%** |\n| 4 | yakumatch | 薬剤師 | 22 | 22/22 | **100.0%** |\n| 6 | phget | 薬剤師 | 1 | 1/1 | **100.0%** |\n| 9 | oshigoto-lab | 医療 | 11 | 11/11 | **100.0%** |\n| 12 | bestcareer | 薬剤師 | 22 | 22/22 | **100.0%** |\n| 13 | pharmapremium | 薬剤師 | 21 | 21/21 | **100.0%** |\n| 18 | nikken-care | 介護 | 12 | 12/12 | **100.0%** |\n| 19 | nikken-nurse | 看護 | 21 | 21/21 | **100.0%** |\n| 20 | cocofump | 介護 | 4 | 4/4 | **100.0%** |\n| 25 | w-medical-9 | 医療 | 25 | 25/25 | **100.0%** |\n| 26 | firstnavi | 看護 | 19 | 19/19 | **100.0%** |\n| 30 | mc-pharma | 薬剤師 | 23 | 22/23 | 98.3% |\n| 32 | yakusta | 薬剤師 | 15 | 13/15 | 96.0% |\n| 35 | kaigokango | 介護/看護 | 24 | 22/24 | 93.3% |\n| 31 | ph-10 | 薬剤師 | 13 | 10/13 | 90.8% |\n| 1 | tsukui-staff | 介護 | 23 | 16/23 | 86.1% |\n| 14 | caresta | 介護 | 16 | 11/16 | 85.0% |\n| 8 | apuro | 薬剤師 | 17 | 14/17 | 84.7% |\n| 16 | pharmalink | 薬剤師 | 18 | 12/18 | 80.6% |\n| 24 | kaigo-work | 介護 | 27 | 21/27 | 77.8% |\n| 5 | mynavi | 薬剤師 | 22 | 15/22 | 71.8% |\n| 10 | yakuzaishisyusyoku | 薬剤師 | 2 | 0/2 | 0.0% |\n| 21 | MRT-nurse | 看護 | 5 | 0/5 | 0.0% |\n\n**要約（Want List、23サイト）：** フィールドレベル：386フィールド中337フィールドがperfect（**87.3%**）。11サイトが100%を達成。コアフィールドhit rate：検出されたコアフィールド121件中108件がperfect（**89.3%**）。コアフィールドカバレッジ：全161コアフィールド中121件を検出（**75.2%**）。\n\n### 4.4 スキーマガイドの効果とコアフィールド分析\n\n**コアフィールド評価。** 実用的有用性を評価するため、求人サイトに普遍的に存在すると想定される7つの「コアフィールド」（給与、勤務地、雇用形態、職種、施設名、勤務時間、休日）を定義した。以下の表は、これらコアフィールドにおけるAuto DiscoverモードとWant Listモードの比較を示す：\n\n| 指標 | Auto Discover | Want List |\n|--------|--------------|-----------|\n| コアフィールド検出数 | 100 / 161 (62.1%) | 121 / 161 (75.2%) |\n| 検出コアフィールドのperfect率 | 96 / 100 (96.0%) | 108 / 121 (89.3%) |\n| 全フィールドのperfect率 | 298 / 350 (85.1%) | 337 / 386 (87.3%) |\n\nWant Listの主たる貢献は**カバレッジの向上**にある。Auto Discoverと比較して13.1ポイント多くのコアフィールドを検出している（75.2% vs 62.1%）。一方、フィールドが特定された場合のhit rateはAuto Discoverの方がやや高い（96.0% vs 89.3%）。これは、Auto Discoverが確信度の高いフィールドのみXPathを生成するのに対し、Want Listは構造的に抽出が困難なフィールドにも対応を試みるためと考えられる。情報検索の用語で言えば、スキーマガイドはシステムをprecision-recallトレードオフ曲線上で移動させる：Auto Discoverは高precisionかつ低recallの保守的な動作をし、Want Listはフィールドあたりの精度をわずかに犠牲にして大幅に広いフィールドカバレッジを実現する。\n\n**スキーマガイドの機構。** 目的フィールドの意味的記述（例：`\"contract\": \"雇用形態（正社員、契約社員、パート等）\"`）を提供することで、Want ListはLLMがDOMパターン認識のみに依存するのではなく、*意味*によってフィールドをマッチングするよう導く。これは、人間のスクレイピング担当者に未知のサイトを調査させる前にデータ辞書を渡すことに類似している。カバレッジの向上は、抽出の*意図*を伝達することが強力なレバーであることを実証している。\n\n**フィールド数の変動。** LLMはランごとに異なる数のフィールドを生成する（Auto Discover）、あるいは認識されないフィールドにnullを返す（Want List）ため、サイトレベルの平均hit rateはラン間で変動しうる。全サイトを通じたフィールドレベルの集計指標（perfectフィールド数 / 全フィールド数）は、サイトレベルの平均よりも安定したシステム性能の尺度を提供する。\n\n**失敗事例。** 2サイト（yakuzaishisyusyoku、MRT-nurse）はAuto Discoverでは機能したにもかかわらず、Want Listで0%となった。両ケースにおいて、LLMが返したフィールドはごく少数（それぞれ2件と5件）であり、XPathパターンに誤りがあった（相対パス `./div[...]` やセレクタの不一致）。これらの失敗は、Want Listプロンプティングと非標準的なサイト構造（Tailwind CSSのユーティリティクラス、非典型的なDOM階層）との相互作用に起因すると考えられ、スキーマガイドがかえってLLMの出力品質を制約するという逆説的な結果を示している。\n\n### 4.5 HTML構造別の結果\n\n| HTML構造 | サイト数 | Perfectフィールド数 (WL) | Hit Rate (WL) |\n|----------------|-------|---------------------|----------------|\n| th/td テーブル | 12 | 189/217 | 87.1% |\n| dt/dd 定義リスト | 5 | 80/90 | 88.9% |\n| dt/dd + th/td 混在 | 4 | 51/53 | 96.2% |\n| div/span (Tailwind等) | 2 | 17/72 | 23.6% |\n\n構造化されたHTMLパターン（dt/dd、th/td）は一貫して高い精度を達成した。混在構造が最も高い性能を示したが、これはLLMにとってより多くの構造的手がかりが利用可能であるためと考えられる。CSSフレームワークのユーティリティクラスを用いたサイト（div/spanベースのレイアウト）は、LLMがフィールド特定に依拠するセマンティックな構造を欠くため、困難であることが判明した。\n\n### 4.6 除外サイト\n\n| カテゴリ | 件数 | サイト |\n|----------|-------|-------|\n| SPA（JSレンダリング必要） | 7 | #7, #11, #15, #22, #27, #28, #29 |\n| HTTPエラー / 認証必要 | 3 | #3 (403), #17 (500), #23 (ログイン) |\n| JS依存コンテンツ | 1 | #34 (空のmainタグ) |\n| URL検出失敗 | 1 | #33 |\n\n### 4.7 工数削減効果\n\n| 指標 | 手動プロセス | XPathGenie |\n|--------|---------------|------------|\n| 1サイトあたりの所要時間（生成のみ） | 5〜6時間 | 約20秒 |\n| 23サイト合計（生成のみ） | 115〜138時間 | 約8分 |\n| 必要スキル | ドメイン知識を持つシニアエンジニア | URLにアクセスできる任意のオペレータ |\n| ページあたりの追加AI費用 | N/A | ゼロ（XPathは再利用可能） |\n\n手動作業の所要時間（5〜6時間/サイト）の推定値は、本医療求人スクレイピングポートフォリオにおける著者らの経験に基づくものであり、他のドメインに一般化できるとは限らない。XPathGenieの所要時間は自動生成ステップのみを計測したものであり、Aladdinによる検証作業には1サイトあたり5〜15分を要する。\n\n### 4.8 トークン効率\n\nHTML圧縮パイプラインはコスト効率の確保に不可欠である。圧縮なしの場合、10ページの生HTML（各約500 KB）を送信すると1リクエストあたり約1,000,000トークン以上を消費し、大半のLLM APIでは実行不可能である。圧縮後（平均97%削減、1ページあたり8,000文字上限）の総トークン消費量は8,000〜18,000である。Genie処理の平均所要時間は1サイトあたり20.7秒（中央値：19.1秒）であった。\n\n### 4.9 失敗事例の分析\n\n体系的な失敗モードを理解するため、最も性能の低かった2サイトについて詳細な分析を行った：caresta（#14、57.9%）およびmynavi（#5、72.3%）。\n\n**caresta（57.9% — 19フィールド中8フィールドが0%）。** 失敗した8フィールドはすべて、テーブルヘッダに対する`text()=`完全一致述語を使用している（例：`//th[text()='給与']/following-sibling::td[1]`）。サイトの生HTMLには空白でパディングされた`<th>`要素（`<th>\\n    給与\\n  </th>`）が含まれており、`text()=`の完全一致は失敗するが`normalize-space()`を用いた等価式であれば成功する。これは圧縮-生成ギャップ（Section 3.1）の典型的な事例である：LLMは`<th>給与</th>`がクリーンに見える圧縮HTMLを参照し、`text()='給与'`述語を生成するが、これは空白を多く含む生HTMLでは失敗する。注目すべきは、同サイトで成功した11フィールドも同じXPathパターンを使用しているが、対象のヘッダにたまたま内部空白がなかったという点であり、この失敗が構造的な問題ではなく空白に固有のものであることが確認される。\n\n**mynavi（72.3% — 26フィールド中6フィールドが0%）。** 失敗フィールドに共通するパターンは`p[contains(@class, 'itemName') and text()='勤務地']/following-sibling::div[1]/p[1]`である。調査の結果、mynaviはCSSフレームワークのユーティリティクラスを広範に使用しており、`itemName`段落要素は圧縮HTMLでは見えない追加の`<div>`層にラップされていることが判明した。`following-sibling::div[1]`セレクタはフレームワークが挿入した中間ラッパーdivのために誤った兄弟要素を対象としている。これは、圧縮HTMLの簡略化された構造がLLMに実際のDOMネスト深度について誤った情報を与える、CSSフレームワーク互換性の問題を示している。\n\n**全サイトに共通する失敗パターン：**\n\n| 失敗モード | 影響サイト | 根本原因 |\n|-------------|---------------|------------|\n| `text()=`述語における空白 | caresta, bestcareer | 圧縮-生成ギャップ |\n| CSSフレームワークのラッパーdiv | mynavi | 圧縮後のDOM深度の不一致 |\n| ラベルテキストの変異 | pharmalink, apuro | 非標準的なラベルの使用（例：「お給料」vs「給与」） |\n| 条件付きコンテンツ | kaigo-work | 特定の求人種別にのみ存在するフィールド |\n\nこれらのパターンは、XPathGenieがフィールド特定のアンカーとしてセマンティックなHTML構造（dt/dd、th/td）に依拠するという暗黙の構造的前提を明らかにしている。ユーティリティファーストのCSSフレームワーク（例：Tailwind CSS）は、セマンティックな階層を非記述的なクラス名を持つ深くネストされた`<div>`・`<span>`要素に平坦化するため、LLMが利用可能な構造的手がかりが減少し、こうしたサイトにおける体系的な性能低下を説明する。\n\nこれらの失敗モードは、2つの主要な改善方向を示唆している：(1) `text()=`に代わる`normalize-space()`の体系的な採用（v3で既に実装済み）、および(2) CSSフレームワークを多用するサイトに対してラッパーdiv構造を保持する適応的圧縮。\n\n### 4.10 再現性\n\nLLMが生成するXPathマッピングのラン間安定性を評価するため、23サイト中21サイトについてWant List評価を3回実行した（`temperature=0.1`）。2サイトは複数ラン分のデータが得られなかった。結果を以下にまとめる。\n\n| 安定性カテゴリ | サイト数 | 説明 |\n|-------------------|-------|-------------|\n| 完全安定（σ = 0） | 8/21 (38%) | 3回全てで同一結果（例：yakumatch, pharmapremium, w-medical-9: 100% ×3） |\n| 安定（0 < σ < 0.05） | 8/21 (38%) | ほぼ同一、軽微な変動のみ |\n| 中程度（0.05 ≤ σ < 0.15） | 3/21 (14%) | 軽度の変動（例：kaigo-work: 83–100%, bestcareer: 91–100%） |\n| 不安定（σ ≥ 0.15） | 2/21 (10%) | 高い分散（phget: 0–100%, MRT-nurse: 0–100%） |\n\n**3回のランにおける全体平均hit rate（21サイトのマクロ平均）：83.1%（大多数のサイトでSD < 0.05）。** 8サイトが分散ゼロの完全安定性を達成した。大半のサイトは安定した結果を生成するが、2サイト（phget、MRT-nurse）はLLMが時折まったく異なるフィールドセットを生成する極端な分散を示した。この不安定性は、LLMのXPath生成をアンカーする構造的手がかりが少ない非標準的なHTML構造（div/spanベースのレイアウト）と相関している。これらの知見はSection 6.1で提起したLLMの非決定性に関する懸念を裏付けるものであり、本番運用では複数回の解析を実行してコンセンサスマッピングを選択することで堅牢性を向上させられることを示唆している。\n\n### 4.11 アブレーション研究\n\nパイプラインの各構成要素の寄与を定量化するため、代表的な5サイトについて4条件（フルパイプライン、HTML圧縮なし、二段階精緻化なし、`normalize-space()`プロンプトガイダンスなし）で評価した。\n\n| 条件 | 平均Hit Rate | Δ vs フル | 備考 |\n|-----------|--------------|-----------|-------|\n| **フルパイプライン** | **88.1%** | — | ベースライン |\n| 圧縮なし | 65.0% | **−23.1pp** | 5サイト中2サイトが失敗（LLM出力の切り詰めによるJSONパースエラー） |\n| 精緻化なし | 88.8% | +0.7pp | Hit rateは安定するが、サイトあたりの検出フィールド数が減少 |\n| normalize-spaceなし | 82.9% | **−5.2pp** | carestaが81.5%から46.2%に低下 |\n\n**主要な知見：**\n\n1. **HTML圧縮が最も重要な構成要素である**（なしで−23.1pp）。生HTMLは実用的なトークン制限を超過し、LLMが切り詰められた、または解析不能なJSONレスポンスを生成する原因となる。解析に成功した場合でも、未圧縮HTMLの先頭8,000文字のみが処理されるため、ページ深部の構造化コンテンツが見落とされ、検出フィールド数が減少する（tsukui-staffで12フィールド vs 30フィールド）。\n\n2. **`normalize-space()`は限定的だが有意な改善を提供する**（なしで−5.2pp）。その影響は空白の多いHTMLを持つサイトに集中している：carestaのhit rateはnormalize-spaceガイダンスなしで半減（81.5% → 46.2%）し、Section 4.9で述べた圧縮-生成ギャップを直接的に確認した。クリーンなHTMLを持つサイト（w-medical-9、MRT-nurse）には影響がなかった。\n\n3. **二段階精緻化はhit rateへの影響が最小**（+0.7pp）だが、フィールドの網羅性に影響する。精緻化なしの場合、マルチマッチXPathが特定のコンテンツセクションに絞り込まれないため、サイトあたりの検出フィールド数が減少する（例：w-medical-9で16フィールド vs 24フィールド）。精緻化メカニズムは主としてフィールドの*数量*を改善するものであり、フィールドごとの*精度*を改善するものではない。\n\n### 4.12 クロスドメイン評価\n\n医療求人領域を超えた汎化性能を評価するため、5つの多様なドメイン（EC（中古車）、不動産（賃貸物件）、レシピ/UGC、飲食店レビュー、ニュース）にまたがる10サイトでXPathGenieを評価した。各ドメインに2サイトを含む。全サイトは日本語のSSRページであり、言語を統制しつつドメインとHTML構造を変化させている。\n\n**Table 7：クロスドメイン評価結果**\n\n| # | サイト | ドメイン | フィールド数 | Perfect | Hit Rate | 時間 (秒) | 備考 |\n|---|------|--------|--------|---------|----------|----------|-------|\n| 1 | carsensor.net | EC | 6 | 5/6 | **83%** | 25 | div/class, specList構造 |\n| 2 | goo-net | EC | 20 | 0/20 | **0%** | 30 | ブランド一覧ページ（後述） |\n| 3 | SUUMO | 不動産 | 10 | 10/10 | **100%** | 65 | table + cassetteitemハイブリッド |\n| 4 | LIFULL HOME'S | 不動産 | 10 | 10/10 | **100%** | 32 | div/classカードレイアウト |\n| 5 | Cookpad | レシピ/UGC | 5 | 5/5 | **100%** | 31 | Tailwind CSS, div/span |\n| 6 | Rakuten Recipe | レシピ | 5 | 4/5 | **80%** | 20 | 従来型HTML構造 |\n| 7 | Tabelog | 飲食店 | 14 | 11/14 | **79%** | 49 | 複合的なレビュー+一覧 |\n| 8 | Hotpepper Gourmet | 飲食店 | — | — | 除外 | — | HTTP 403（ボット保護） |\n| 9 | Yahoo! News | ニュース | 7 | 1/7 | **14%** | 26 | CSS-in-JS (styled-components) |\n| 10 | NHK NEWS WEB | ニュース | — | — | 除外 | — | HTTP 403（ボット保護） |\n\nアクセス拒否サイト（2件）および誤ったページタイプ（1件）を除外すると、クロスドメイン評価は5ドメインにまたがる7サイトで**マクロ平均hit rate 79.4%**を達成した。2サイトが100%（SUUMO、Cookpad）、さらに2サイトが80%超（carsensor 83%、Rakuten Recipe 80%）であった。\n\n**ドメイン別の失敗分析。**\n\n- **EC（goo-net、0%）。** 評価対象URLは個別の車両詳細ではなく、車種名と台数を列挙するブランド一覧ページ（例：「プリウス (8,873)」）であった。LLMは20の車両詳細フィールド（価格、走行距離、排気量等）を正しく特定したが、これらのフィールドは一覧ページには存在しない。これは、XPathGenieの精度が適切なページタイプの提供に依存することを示しており、全てのXPathベース抽出システムに共通する制約である。\n\n- **ニュース（Yahoo! News、14%）。** Yahoo! Newsはビルドハッシュクラス名（例：`sc-1t7ra5j-10`、`cfHAOL`）を持つCSS-in-JS（styled-components）を使用しており、これらはデプロイごとに変化する。このような非セマンティックかつ一時的なクラス名は、XPath生成のための安定した構造的アンカーを提供しない。位置ベースのDOMトラバーサルを用いた`date`のみが正常に抽出された。これはクラス名依存のXPath戦略の根本的な限界を示している。\n\n- **飲食店（Tabelog、79%）。** 14フィールド中11フィールドが正常に抽出され、restaurant_name、rating_score、area_genre、価格帯等が含まれる。抽出に失敗した3フィールド（comment_author、comment_text、comment_title）は、検索結果一覧ページには存在しないユーザーレビューコンテンツを対象としており、抽出の失敗ではなくページタイプの不一致の事例である。\n\n- **アクセス拒否サイト（Hotpepper Gourmet、NHK NEWS WEB）。** これらのサイトはHTTP 403レスポンスを返し、プログラムによるアクセスをブロックした。これはアクセス上の制約であり、抽出能力の限界ではない。\n\n**構造的知見。** クロスドメインの結果はSection 4.5の知見を補強するものである：XPathGenieはドメインによらず、セマンティックなHTML構造（th/td、dt/dd、BEM命名規則のクラス名）を持つサイトで良好に機能し、非セマンティックなクラス名を生成するCSS-in-JSフレームワークでは性能が低下する。注目すべきは、CookpadはTailwind CSSを使用しているにもかかわらず100%を達成した点であり、制約要因はユーティリティクラスそのものではなく、DOM階層におけるセマンティックな構造の存在であることを示している（Cookpadはセマンティックな`<h2>`、`<a>`、構造化コンテナをTailwindユーティリティと併用している）。より広い観点から、これらの結果は**半構造化コンテンツ仮説**を支持する：XPathGenieはセマンティックなHTML構造を持つコンテンツ指向のページにおいてドメインに依存せず有効であるが、ナビゲーション主体のページ、動的にレンダリングされるSPA、および一時的なクラス名を用いるCSS-in-JSサイトでは性能が低下する。重要なのは、これらの失敗事例はアルゴリズムの欠陥ではなく**構造的前提の違反**を反映しているという点である：goo-netは抽出スキーマとページタイプが一致しないために失敗しており（問題定義の不一致）、Yahoo! NewsはCSS-in-JSがXPathベース抽出が本質的に必要とする安定した構造的アンカーを排除するために失敗している。いずれもXPathパラダイム自体の境界条件であり、XPathGenieの実装固有の弱点ではない。\n\n### 4.13 英語クロスドメイン評価\n\n多言語汎化性能を評価するため、主要評価（Section 4.1）と同じ複数ページバリデーションプロトコルを用いて、英語Webサイトを対象とした追加のクロスドメイン評価を実施した。XPathGenieのXPath生成は言語ではなく構造（DOM階層、タグ名、クラス名）に基づくが、日本語以外の言語でセマンティックなフィールド名やHTMLコンテンツを解釈するLLMの能力は実証的に検証されていなかった。**10の英語Webサイト（10ドメイン）** を対象に、各3ページ（計30ページ）、Auto Discoverモードで評価を実施した。\n\n**Table 8：英語クロスドメイン評価 — 複数ページHit Rate（10サイト）**\n\n| # | サイト | ドメイン | ページ数 | フィールド数 | Perfect | Hit Rate | 時間 (秒) | 備考 |\n|---|------|--------|-------|--------|---------|----------|----------|-------|\n| 1 | GitHub | 開発/OSS | 3 | 6 | 6/6 | **100%** | 10.7 | react, vue, svelte |\n| 2 | Quotes to Scrape | 引用一覧 | 3 | 4 | 4/4 | **100%** | 18.2 | /page/1-3/ |\n| 3 | Hacker News | ニュース/フォーラム | 3 | 3 | 2/3 | **89%** | 33.5 | コメント重視のスレッド |\n| 4 | StackOverflow | Q&A | 3 | 12 | 7/12 | **86%** | 44.3 | コアQ&A 100%、著者フィールド 67% |\n| 5 | PyPI | パッケージレジストリ | 3 | 10 | 8/10 | **80%** | 45.5 | requests, flask, numpy |\n| 6 | Wikipedia | 百科事典 | 3 | 4 | 3/4 | **75%** | 33.5 | コア100%、セクション見出し失敗 |\n| 7 | Python PEP | ドキュメント | 3 | 13 | 2/13 | **21%** | 16.5 | PEP-8 vs PEP-20の構造不一致 |\n| 8 | Amazon | EC | 3 | 2 | 2/2 | **100%**† | — | ボット保護：最小限のHTMLのみ返却 |\n| 9 | Goodreads | 書籍/レビュー | 3 | 0 | — | **0%** | — | React SSR: 740KB→圧縮後278バイト |\n| 10 | IMDb | エンタメ | 3 | — | — | — | タイムアウト | 1.5MB HTMLが処理限界を超過 |\n\n†Amazonは2つのメタデータフィールド（product_path、search_keywords）のみを空値で返しており、ボット保護HTMLであることを示す。\n\n**全体指標（10サイト）：** Goodreadsを0%、IMDbを0%、Amazonを除外（ボット保護）として計算すると、**スコア可能な9サイトのマクロ平均hit rateは61.2%**。**有意なフィールド抽出が行われた7サイト**（Amazon、Goodreads、IMDbを除く）では、マクロ平均は**78.7%**。\n\n**Table 9：フィールド別バリデーション詳細 — 上位パフォーマー**\n\n| サイト | フィールド | 信頼度 | サンプル値 |\n|------|-------|-----------|---------------|\n| GitHub | repository_name | 100% | react, vue, svelte |\n| GitHub | stars_count | 100% | 243k, 208k, 83.3k |\n| StackOverflow | question_title | 100% | \"Why is processing a sorted array faster...\" |\n| StackOverflow | vote_count | 100% | 3質問の投票数 |\n| StackOverflow | tags | 100% | java, c++, python tags |\n| Wikipedia | title | 100% | Web scraping, Data mining, Machine learning |\n| Quotes to Scrape | quote_text | 100% | 正しい帰属付きの引用文 |\n| Quotes to Scrape | author_name | 100% | Albert Einstein, J.K. Rowling等 |\n| Hacker News | comment_text | 100% | コメント本文全体 |\n| PyPI | project_title | 100% | Requests, Flask, numpy |\n\n**主要な知見：**\n\n- **10ドメインにわたる言語横断的適用可能性の予備的証拠。** 2サイトが100%のhit rateを達成し（GitHub、Quotes to Scrape）、さらに4サイトが75%超（Hacker News 89%、StackOverflow 86%、PyPI 80%、Wikipedia 75%）となった。これは、セマンティックなHTMLを持つ英語サイトにおいてXPathGenieの構造ベースのアプローチが有効に機能することを示している。これらの結果は、日本語の主要評価において23サイト中11サイトが100%を達成した結果と同等である。\n\n- **StackOverflow：深いフィールド発見。** Auto Discoverは、質問メタデータ（title、votes、views、dates、tags — すべて100%）および著者プロフィール詳細（reputation、badges — community wikiの投稿で著者カードがないため67%）を含む12フィールドを特定した。これは基本的なページメタデータを超えてフィールドを発見するシステムの能力を示している。\n\n- **ページ構造の異質性が汎化を制限する。** Python PEPの21%というhit rateは特有の失敗モードを示している：PEP-8（メタデータテーブルを含む包括的なスタイルガイド）とPEP-20（最小限の「Zen of Python」）は根本的に異なるページ構造を持つ。Auto DiscoverはPEP-8から13のXPathを生成したが、これらは汎化しなかった。対象フィールドを指定したWant Listモードであれば改善が見込まれる。\n\n- **大規模・動的HTMLは依然として困難。** Goodreads（React SSR: 740KB→278バイト、Appendix B.2参照）、IMDb（1.5MBでタイムアウト）、Amazon（ボット保護）は、XPathGenieがアクセス可能でサーバーサイドレンダリングされたセマンティックな構造を持つHTMLを必要とすることを確認した。この制約はJavaScriptを用いないスクレイピング手法全般に共通するものである。\n\n- **言語を超えたドメインの広がり。** 成功した7つの英語サイトは、開発/OSS、引用一覧、ニュース/フォーラム、Q&A、パッケージレジストリ、百科事典、ドキュメントの各ドメインにまたがっており、日本語評価のドメイン（医療、不動産、レシピ、飲食店、ニュース）とは一切重複しない。これにより、クロスドメインカバレッジの総計は**2言語にわたる12以上のドメイン**に拡大された。\n\n**日本語クロスドメイン評価との比較。** 英語評価における成功サイトのマクロ平均hit rate（78.7%）は、日本語クロスドメイン評価（79.4%、Section 4.12）と同等である。両評価は同じパターンを示す：セマンティックに構造化されたHTMLでは高精度（GitHub 100%、SUUMO 100%、Cookpad 100%）、異質なページ構造（PEP 21%、Yahoo! News 14%）やJavaScriptレンダリングのサイト（Goodreads 0%）では性能が低下する。\n\n![Figure 3: Cross-Domain / Cross-Language Hit Rate](figures/cross_domain.png)\n\n**HTMLスナップショットのアーカイブ。** 全HTMLページ（10サイト計30ファイル）を再現性確保のためスナップショットとしてアーカイブした（`tests/e2e/snapshots/260218_en_v2/`および`260218_en_v3/`）。これによりオフラインでの再評価が可能となり、再現可能な評価プロトコルが確立された。1サイトあたり3ページのプロトコル（日本語評価では10ページ）は、手動でのURL選定を伴うスナップショットベース評価のコストを反映しており、今後の評価では統計的堅牢性のため10ページ以上への拡張が望まれる。\n\n### 4.14 SWDEベンチマーク評価\n\n教師ありWeb抽出システムとの比較を可能にするため、SWDE（Structured Web Data Extraction）ベンチマーク（Hao et al., 2011）のサブセットでXPathGenieを評価した。SWDEは8つのバーティカルにまたがる80サイトのアーカイブHTMLページと正解フィールドアノテーションを含む標準的な評価データセットである。本評価は、共有データセット上でのXPathGenieのゼロショットアプローチと教師ありベースラインとの初の直接的なF1比較を提供する。\n\n**プロトコル。** SWDE全8バーティカルから22サイト（バーティカルあたり2〜3サイト）を選定し、公開データセットミラー（W1ndness/SWDE-Dataset）からサイトあたり10件のアーカイブHTMLページ（計220ページ）と対応する全正解アノテーションをダウンロードした。各サイトについて、最初の3ページを入力として、バーティカルの標準フィールド名（例：jobバーティカルでは`title`、`company`、`location`、`date_posted`）をWant Listモードで指定してXPathGenieに与えた。生成されたXPathを`lxml`を用いて全10ページに適用し、抽出値を正規化テキストマッチング（空白正規化、大文字小文字の無視、部分一致のための部分文字列包含）で正解と比較した。フィールドごとに標準的なPrecision、Recall、F1を算出した。\n\n**結果。** Table 6にバーティカル別の性能をまとめる。\n\n**Table 6：SWDEベンチマーク結果（バーティカル別、22サイト、各10ページ、ゼロショット）。**\n\n| バーティカル | サイト | 検出フィールド / 全体 | マクロF1（全フィールド） | F1（検出フィールドのみ） | 最良サイト |\n|---|---|---|---|---|---|\n| Job | 3/3 | 8/12 | 0.667 | **1.000** | dice (F1=1.0, 4/4フィールド) |\n| Movie | 1/2 | 1/8 | 0.125 | **1.000** | yahoo (title F1=1.0) |\n| Restaurant | 1/3 | 4/12 | 0.325 | **0.975** | fodors (F1=0.975, 4/4フィールド) |\n| Auto | 3/3 | 7/12 | 0.500 | **0.857** | yahoo (F1=1.0, 4/4フィールド) |\n| University | 2/3 | 4/12 | 0.246 | **0.737** | usnews (F1=1.0, 2/2検出) |\n| NBA Player | 2/3 | 8/12 | 0.333 | **0.500** | wiki (name/team F1=1.0) |\n| Book | 2/2 | 6/10 | 0.157 | 0.262 | borders (author F1=0.87) |\n| Camera | 1/3 | 2/9 | 0.015 | 0.067 | beachaudio (model F1=0.13) |\n| **全体** | **15/22** | **40/87** | **0.317** | **0.689** | — |\n\n![Figure 2: SWDE Benchmark Results by Vertical](figures/swde_results.png)\n\n**AXEとの比較。** AXE（arXiv:2602.01838, 2026）はSWDEフルデータセットで、ドメイン固有のラベルで学習された0.6Bパラメータの教師ありモデルを用いてF1 88.1%を報告している。XPathGenieは、未検出フィールドをF1=0として計算した厳密なマクロF1で31.7%、XPathが正常に生成されたフィールドでは68.9%を達成した。この比較は教師ありシステムに対する優劣を主張するものではなく、学習データゼロの制約下でのゼロショットXPath生成の実現可能性とその特性を示すものである。この差は、以下のパラダイムの根本的な違いを考慮すれば当然である：\n\n- **AXE**：ラベル付き学習データによる教師あり学習、SWDEスキーマに最適化、全フィールドで評価。\n- **XPathGenie**：学習データなしのゼロショット推論、SWDEサイトへの事前露出なし、同一フィールド定義で評価。\n\n**差異の分析。** 性能差は主に以下の3つの要因に起因する：\n\n1. **アーキテクチャのスコープ不一致**：XPathGenieの圧縮パイプラインは`<body>`コンテンツを対象とし、`<title>`タグを含む`<head>`要素を破棄する。SWDEの複数のフィールド（例：jobバーティカルの`title`）は`<title>`からの抽出が最も自然であるが、XPathGenieはこれを試みない。同様に、`date_posted`のようなフィールドはページ本文中に構造的に特定可能な要素として存在しない場合がある（非構造化テキストに埋め込まれている、あるいは完全に不在）。これらは抽出の失敗ではなく、設計上の境界を示している—XPathGenieは構造化された本文コンテンツの抽出を目的としており、メタデータ抽出を目的としていない。\n\n2. **フィールド発見カバレッジ（46%）**：XPathGenieは対象87フィールドのうち40フィールドでXPathを生成した。上記のアーキテクチャ上のスコープ不一致に加え、複雑またはレガシーなHTML構造（2008〜2011年代のページ）においてLLMがフィールドの特定に失敗する場合があった。特に、明確な構造的マーカーのない非セマンティックなコンテナ内にフィールド値が埋め込まれている場合に顕著であった。*検出された*フィールドについては、70%がF1 ≥ 0.5を、60%がF1 = 1.0（完全抽出）を達成した。\n\n3. **サイトレベルの失敗（23%）**：22サイト中5サイトがフィールドゼロを返した。2つの失敗モードが支配的である：(a) 圧縮HTMLがLLMの実効的な解析能力を超過（camera-amazon: 圧縮後114KB、camera-buy: 圧縮後396KB）、(b) HTML構造が複雑すぎて圧縮パイプラインが意味のある構造的シグナルを保持できない（restaurant-opentable: JavaScriptヘビーなページから圧縮後2.3KB）。\n\n![Figure 4: HTML Compression — Raw vs Compressed Size](figures/compression_comparison.png)\n\n**示唆。** SWDEの結果は明確なパターンを示している：**XPathGenieがXPathの生成に成功した場合、抽出は非常に高精度である**（検出フィールドF1 = 0.689、検出フィールドの60%がF1 = 1.0）。主要な制約は抽出品質ではなくフィールドの*発見*——未知のページ構造において関連するHTML要素を特定するLLMの能力——にある。このことは、圧縮パイプラインとフィールド発見のためのLLMプロンプティングの改善が大きな改善をもたらす一方、コアのXPath生成メカニズムは健全であることを示唆している。\n\n特筆すべき成功例として、jobバーティカル（3サイト、検出フィールドで全てF1 = 1.0）、auto-yahoo（4フィールド全てF1 = 1.0）、restaurant-fodors（4フィールド、F1 = 0.975）が挙げられ、セマンティックなHTML構造を持つサイトにおいてはゼロショット設定であっても教師ありシステムに匹敵する性能を達成できることを示している。\n\n**SWDEにおける意味的正確性。** 手動意味評価（Section 3.7.7、本番サイトで100サンプル、意味的正確性95.0%）を補完するため、XPathが正常に生成された全SWDEフィールド-値ペアに対して自動意味分類を実施した。各抽出値をSWDE正解と比較し、Correct（正規化後の完全一致）、Partial（部分文字列包含または50%以上のトークン重複）、Wrong（意味的重複なし）に分類した。\n\n**Table 7：意味的正確性 — 手動評価（本番サイト）vs 自動評価（SWDEベンチマーク）。**\n\n| 評価 | サンプル数 | Correct | Partial | Wrong | 意味的正確性 |\n|---|---|---|---|---|---|\n| 手動（23 JP本番サイト） | 100 | 82% | 13% | 5% | **95.0%** |\n| 自動（22 SWDEサイト） | 400 | 47.0% | 31.0% | 22.0% | **78.0%** |\n\nSWDEにおける意味的正確性の低下（78.0% vs 95.0%）は想定の範囲内である。SWDEのページは2008〜2011年にアーカイブされたレガシーHTML構造であり、失敗事例の一部はXPathの根本的な誤りではなくエディション（版）の不一致（例：XPathGenieがハードカバーの出版社を抽出する一方、正解がペーパーバック版を記載）に起因する。バーティカル別の結果がこのパターンを裏付けている：job（100%）、movie（100%）、restaurant（100%）は完全な意味的正確性を達成する一方、book（52%）とcamera（10%）が大部分の誤りを占めている。\n\n**再現性。** 本評価で使用した全SWDEのHTMLページおよび正解ファイルは`data/swde/`にアーカイブされており、評価スクリプトは`docs/evaluation/swde_real_eval.py`で利用可能であり、これらの結果の正確な再現が可能である。評価メタデータ：クロール日時 2026-02-18T17:20Z、User-Agent `XPathGenie-Eval/1.0`、LLMモデル `gemini-2.5-flash`（`temperature=0.1`）。英語クロスドメイン評価（Section 4.13）では30件の全HTMLスナップショットが`tests/e2e/snapshots/`に追加アーカイブされている。\n\n## 5. 設計原則\n\n### 5.1 \"Why > What\"— LLM への意図の伝達\n\nXPathGenie のプロンプト設計における中核的な原則は、制約が *何であるか* を示すだけでなく、*なぜ* その制約が必要かを LLM に伝えることである。たとえば、`contains(@class, ...)` の使用を指示する際には「クラス属性は複数の値を持つことが多いため」という理由を併記している。同様に、コンテナプレフィックスの禁止についても、正しい出力と誤った出力の対比例を添えて説明している。\n\nこの原則は Want List モードにも適用されている。フィールドの説明文は意味的な意図を示すシグナルとして機能する。たとえば `\"contract\": \"雇用形態 (employment type)\"` という記述は、単に「contract」フィールドを探すよう指示するだけでなく、*なぜ* 特定の HTML 要素が該当するかを LLM に伝える。該当要素には「正社員」「契約社員」「パート」といった雇用形態に関する情報が含まれるためである。これにより、LLM は「雇用形態」「就業形態」「Employment Type」などの異なるラベルを同一フィールドに対応付けることが可能となる。\n\n機械的絞り込み（Section 3.4, Tier 1）における中間コンテナの自動検出も同じ原則の発現である。コンテナのクラス名をハードコーディングするのではなく、祖先チェーンを走査して動的に発見することで、サイト固有の設定なしに任意のサイト構造に適応できる。\n\n### 5.2 役割の逆転\n\n従来の Web スクレイピングのワークフロー：\n- **人間**: XPath を記述する（創造的だが誤りを生じやすい）\n- **機械**: XPath を実行する（機械的かつ信頼性が高い）\n\nXPathGenie のワークフロー：\n- **機械**: XPath を記述する（LLM 推論＋機械的絞り込み）\n- **人間**: XPath を検証する（Aladdin による抽出値の目視確認）\n\n一方が作成し他方が検証するという構造的関係は維持しつつ、役割が逆転している。人間は「この値は正しそうだ」と判断することには長けているが、`//dl[dt[normalize-space()='給与']]/dd` をゼロから構築することは得意ではない。一方、機械は HTML 構造全体にわたる体系的なパターンマッチングには優れるが、文脈に即した抽出値の品質判断は不得手である。\n\n### 5.3 コスト最適化 — AI は一度、DOM は永続\n\nXPathGenie の最も重要なアーキテクチャ上の決定は、LLM の呼び出しをサイトマッピングごとに正確に 1 回（AI 精緻化が発動する場合は 2 回）に限定することである。その出力は再利用可能な XPath 式の集合であり、決定論的でポータブルかつ AI インフラなしで実行可能である。\n\n形式的に述べると、*n* ページを持つサイトに対して、従来のページ単位 LLM 抽出は *O(n)* の AI コストを要するのに対し、XPathGenie のコストモデルは *O(1)* の AI コスト（一度限りのマッピング生成）に加え、追加 AI コストゼロの *O(n)* の決定論的 DOM クエリで構成される。10,000 ページのサイトであっても、XPathGenie のコストは 1 ページの場合と同一であり、マッピング生成は一度のみ、以降は純粋な `lxml.xpath()` 呼び出しのみとなる。\n\n二段階精緻化はさらにコストを最適化する。Tier 1 の機械的絞り込みは DOM 走査によって大半の複数マッチケースを解決し（AI コストゼロ）、値の曖昧性解消が真に必要なケースにのみ、より高コストな AI 再推論を留保する。\n\n**コスト最適化を意識した圧縮範囲の設計。** XPathGenie の圧縮パイプラインは `<head>` メタデータ（`<title>` タグや `<meta>` タグを含む）を除外し、`<body>` コンテンツのみを対象とする。これは本番クローリングの要件に基づく意図的なトレードオフである。定期クローリングパイプラインでは、投稿日などの時間的メタデータは、信頼性の低いページ埋め込みの日付ではなく、クローラ自身の観測スケジュール（一意のレコード ID に紐づく初回クロール時刻）から導出されるのが一般的である。同様に、本番システムでは `<title>` タグよりもページ本文から抽出されたコンテンツタイトルが好まれる。`<title>` タグにはレコードの実際の名称とは無関係なサイトブランディングや SEO 修飾語が含まれることが多いためである。HTML 圧縮は LLM のトークン消費に直接影響するため、クローリングインフラで既に利用可能なメタデータを除外することで、分析あたりの不要なトークン支出を回避している。\n\n## 6. 制限事項と今後の課題\n\n**Single-Page Application（SPA）対応。** XPathGenie は現在、HTTP リクエストによる生の HTML 取得に依存している。JavaScript でコンテンツを動的にレンダリングするサイト（React, Vue, Angular による SPA）では、空またはスケルトンの HTML が返されるため、XPath 生成が不安定もしくは不可能となる。ヘッドレスブラウザ（例: Playwright）を利用した JavaScript レンダリング後の HTML 取得は、今後の拡張として計画している。\n\n**サイト構造の変化。** 生成された XPath は、分析時点のサイトの DOM 構造に本質的に依存する。サイトのリデザインや構造変更が行われると、XPath が機能しなくなる可能性がある。定期的な再分析メカニズムや変更検知システムの導入により、本番環境での堅牢性を向上させることができる。\n\n**圧縮-生成ギャップ。** HTML 圧縮パイプラインは空白の正規化やテキストの切り詰めを行うため、LLM が参照する圧縮済み HTML と、生成された XPath が評価される生の HTML との間に構造的な乖離が生じる。たとえば、`<td>\\\\n    勤務地\\\\n  </td>` は `<td>勤務地</td>` に圧縮されるため、`text()='勤務地'` は圧縮 HTML では成功するが生 HTML では失敗する。XPath 述語における `normalize-space()` の採用により、空白に起因するケースは緩和される。圧縮器が誤ったコンテンツ領域を選択するセクション選択エラーについては、対話型ツール Jasmine（Section 3.7）が人間介入のエスケープ手段を提供する。残余の圧縮アーティファクト（例: 切り詰められたテキストノード、除去された空要素）が XPath の妥当性に影響を及ぼすことがあり、生成後の XPath 正規化パスの導入によりこのギャップをさらに縮小できる可能性がある。\n\n**CSS フレームワークおよび CSS-in-JS との互換性。** ユーティリティクラス型 CSS フレームワーク（例: Tailwind CSS）を使用するサイトでは、意味的な情報が非記述的なクラス名（`w-11/12`, `flex`, `gap-2`）を持つ深くネストされた `<div>` や `<span>` 要素にエンコードされるため、精度が低下する。CSS-in-JS フレームワーク（例: styled-components, Emotion）はさらに根本的な課題を呈する。クラス名がビルド時のハッシュ値（例: `sc-1t7ra5j-10`, `cfHAOL`）であり、デプロイごとに変化するため、XPath 生成のための安定した構造的アンカーが一切存在しない。クロスドメイン評価（Section 4.12）でもこれが確認された。Yahoo! ニュース（styled-components）のヒット率はわずか 14% であったのに対し、Cookpad（意味的な HTML コンテナを伴う Tailwind CSS）は 100% を達成した。このことは、制限要因がユーティリティクラスそのものではなく、DOM 階層における意味的構造の有無であることを示している。\n\n**teddy_crawler との統合。** YAML エクスポート形式は teddy_crawler Web クローリングフレームワークとの互換性を考慮して設計されている。パイプライン設定の自動生成など、より深い統合により、マッピング生成と本番抽出の間のギャップをさらに縮小できる。\n\n**圧縮の忠実度。** 積極的な圧縮（30 文字でのテキスト切り詰め、ノイズパターンの除去）により、XPath 構築に関連する構造要素が除去されることがある。複雑なページに対してより多くの構造を保持する適応的圧縮の導入により、エッジケースでの精度を改善できる可能性がある。\n\n**多言語への汎化。** 主要評価は日本語 Web サイトを対象としている。補足的な英語評価（Section 4.13）では 7 ドメイン・7 サイトでの言語横断的な適用可能性が確認されたが、他言語（例: 右書き文字、日本語以外の CJK 言語）での性能は実証的に検証されていない。\n\n**モデルへの依存性。** すべての評価結果は Gemini 2.5 Flash を用いて得られたものである。本アプローチはモデル固有のファインチューニングではなく、構造化プロンプティングと JSON モード出力に依拠しており、他の高性能 LLM への移植可能性が示唆されるが、これは実証的に検証されていない。より小規模なモデルや異なる訓練を受けたモデルでは性能が異なる可能性がある。\n\n**エスカレーション率の一般化。** 13% のエスカレーション率（Section 3.7.6）は医療系求人サイトで計測されたものである。クロスドメイン評価（Section 4.12）は、構造的に多様なドメイン、特に CSS-in-JS や非意味的 HTML を使用するドメインではエスカレーション率がより高くなり、Jasmine を介した人間の介入がより頻繁に必要となる可能性を示唆している。\n\n**再現性の制約。** 主要評価対象ページ（23 の日本語医療系サイト）の HTML スナップショットは評価時にアーカイブされていない。本番 Web サイトは経時的に変化するため、保存された結果ファイルのみからは正確な評価の再現が不可能である。英語のクロスドメイン評価（Section 4.13）では、分析結果と併せて HTML スナップショットをアーカイブすることでこの問題に対処し、今後の実験のための再現可能な評価プロトコルを確立している。\n\n**正解データとの比較。** 現行のヒット率指標は抽出カバレッジ（XPath が非空値を返すかどうか）を測定するものであり、意味的正確性（意図されたフィールドに対して正しい値が抽出されるかどうか）を測定するものではない。意味的正確性の評価（Section 3.7.7）では 100 サンプルの手動レビューにより部分的にこの問題に対処しており、SWDE ベンチマーク評価（Section 4.14）は F1 値に基づく初の正解データ比較を提供しているが、対象は限定的（SWDE 80 サイト中 22 サイト、各 10 ページ）である。全サイト・全ページにわたる完全な SWDE 評価の実施により、これらの主張をさらに強化できる。\n\n### 6.1 妥当性への脅威\n\n現行の評価の妥当性を制限する要因がいくつか存在する：\n\n- **LLM の非決定性。** `temperature=0.1` を設定して準決定論的な出力を得ているものの、モデルの更新、API レベルのバッチ処理、およびサンプリングに内在する確率性により、LLM の応答は実行間で変動しうる。報告された結果は単一実行に基づくものであり、完全な再現性は保証されない。\n- **ドメインカバレッジ。** 主要評価は 1 ドメイン（日本語の医療系求人）の 23 サイトを対象としており、5 ドメイン・10 サイトの日本語クロスドメイン評価（Section 4.12）および 10 ドメイン・10 サイトの英語クロスドメイン評価（複数ページ検証付き、Section 4.13）で補完している。これらの結果は構造化 HTML サイトにおける言語横断的・ドメイン横断的な汎化性を示しているが、CSS-in-JS フレームワークや SPA に対する性能は限定的である。\n- **手作業工数見積もりの主観性。** 手作業ベースラインとする 5〜6 時間は、特定のサイトポートフォリオとエンジニアリングワークフローに基づく著者自身の経験に依拠している。エンジニア、ツール、サイトの複雑さが異なれば、ベースラインは大きく異なりうるため、工数削減の比較は本質的に近似的なものである。\n- **ヒット率と正確性。** 評価指標であるヒット率は XPath が非空値を返すかどうかを測定するものであり、返された値が意味的に正しいかどうかを測定するものではない。あるフィールドがヒット率 100% を達成しながらも誤ったデータを抽出している可能性がある。本番運用においては、Aladdin による人間の検証を引き続き推奨する。\n\n## 7. 結論\n\nXPathGenie は、LLM ベースの XPath 生成を積極的な HTML 圧縮、決定論的な複数ページ検証、および二段階精緻化メカニズムと組み合わせることで、本番 Web サイトにおいて高い抽出カバレッジを達成できることを実証した。23 の日本語医療系求人サイトと、5 つの追加ドメイン（EC、不動産、レシピ、レストランレビュー、ニュース）にまたがる 10 のクロスドメインサイトを対象とした評価において、スキーマ指定型の生成（Want List モード）でフィールドレベルのヒット率 87.3%（全検証ページで 386 フィールド中 337 フィールドが非空値を返した）を達成し、23 サイト中 11 サイトが 100% に到達した。この指標は意味的正確性ではなく抽出の安定性を測定するものであり、本番運用においては Aladdin による人間の検証を引き続き推奨する。医療系以外の日本語 7 サイトを対象としたクロスドメイン評価ではマクロ平均ヒット率 79.4% を達成し、2 サイトが 100% に到達しており、本アプローチが元の医療系求人ドメインを超えて汎化することが確認された。10 ドメイン・10 サイト（各 3 ページ）を対象とした英語評価では、成功した 7 サイトでマクロ平均ヒット率 78.7% を達成し、GitHub と Quotes to Scrape が 100%、StackOverflow が 86% であった。これは XPathGenie の構造的アプローチが言語を超えて汎化するという予備的な証拠を提供するものである。React SSR サイトに対する失敗分析（Appendix B.2）は、制限が XPath 生成ではなく HTML 取得レイヤにあることを確認した。\n\n求人サイトに普遍的に存在する 7 つの「コアフィールド」（給与、勤務地、雇用形態、職種、施設名、勤務時間、休日）を用いた実践的評価では、Auto Discover が検出コアフィールドに対してヒット率 96.0% を達成し、Want List はコアフィールドのカバレッジを 62.1% から 75.2% に改善した。この知見は、スキーマ指定が主として改善するのは *抽出精度* ではなく、システムが *何を探すか* であることを確認するものであり、初見のサイトを調査する前にスクレイピング担当者にデータ辞書を渡すことに類似している。\n\n圧縮-生成ギャップから重要なエンジニアリング上の知見が得られた。HTML 圧縮器は生 HTML に残存する空白を正規化するため、`text()=` 述語が検証時に失敗する。LLM が生成する XPath に `normalize-space()` を採用することでこのギャップは解消され、空白の多い HTML を持つサイトの精度が劇的に向上した（例: ph-10: 0% → 90.8%）。ギャップが空白の不一致ではなくセクション選択の誤りとして顕在化する場合には、対話型ツール Jasmine（Section 3.7）がエスカレーションパスを提供する。自動ヒューリスティクスが失敗した際に、人間がワンクリックで正しいコンテンツセクションを選択すれば、残りのパイプラインは自動的に進行する。この三つのツールによるアーキテクチャ — 生成の Genie、選択の Jasmine、検証の Aladdin — は、各エージェントの強みに応じて認知的負荷を分配する。AI がパターンマッチングとコード生成を、人間が意味的認識と品質判断を担う。\n\n```mermaid\ngraph LR\n    subgraph \"AI-Driven\"\n        G[\"🧞 Genie<br/>XPath Generation<br/>~20 sec/site\"]\n    end\n    subgraph \"Human-in-the-Loop\"\n        J[\"🌸 Jasmine<br/>Section Selection<br/>13% escalation rate\"]\n        A[\"🔮 Aladdin<br/>Bulk Verification<br/>5–15 min/site\"]\n    end\n    G -- \"Auto success<br/>87% of sites\" --> A\n    G -- \"Escalation<br/>13% of sites\" --> J\n    J -- \"Corrected section\" --> G\n    A -- \"Approved mappings\" --> E[\"📦 Export<br/>JSON / YAML\"]\n\n    style G fill:#7c5cfc,color:#fff\n    style J fill:#ff9800,color:#fff\n    style A fill:#4caf50,color:#fff\n    style E fill:#90caf9,color:#000\n```\n\nより広い観点から見ると、圧縮-生成ギャップは一般的な原則を例示している。LLM 推論の前に入力の表層形式を変換するあらゆる変換は、推論時の表現と実行時の環境との間に意味的整合性のリスクをもたらす。これは、LLM が前処理された入力から実行可能なコードを生成するシステムにおいて広く生じうる問題の一類型である。\n\nSWDE ベンチマーク評価（Section 4.14）は、教師ありシステムとの初の直接的な F1 比較を提供する。SWDE の全8バーティカルにわたる 22 サイトにおいて、XPathGenie は XPath が正常に生成されたフィールドで F1 = 0.689（未検出フィールドを含む厳密 F1 = 0.317）を達成した。これに対し AXE の教師あり F1 は 88.1% であった。この差は主にフィールド発見カバレッジ（46%）に起因するものであり、抽出精度そのものの問題ではない — 検出フィールドの 60% が完全な F1 = 1.0 を達成している。この結果は、XPathGenie のコア抽出メカニズムが健全であり、フィールド発見の改善（圧縮とプロンプティングの強化による）が最もレバレッジの高い改善機会であることを確認するものである。\n\n本システムのアーキテクチャ上の洞察 — AI をページごとの抽出ではなく一回限りのマッピング発見に使用すること — により、初期生成後の運用コストはゼロとなる。同一値重複を機械的に解決し、真に曖昧なケースにのみ AI 再推論を留保する二段階精緻化メカニズムは、決定論的前処理を最大化することで AI 呼び出しを最小化するという、より広範な設計原則を体現している。Aladdin による人間介入型の検証ツールと合わせて、XPathGenie は機械が作成し人間が検証するという完全なワークフローを確立し、Web データ抽出における従来の分業を逆転させた。実際のサイトあたりのエンドツーエンド所要時間は、自動生成（約 20 秒）と Aladdin による人間の検証（5〜15 分）を含めて約 20 分であり、手作業による XPath 記述に通常要する 5〜6 時間と比較して大幅に短縮されている。\n\n## References\n\n1. Kushmerick, N., Weld, D. S., & Doorenbos, R. (1997). Wrapper induction for information extraction. *Proceedings of the 15th International Joint Conference on Artificial Intelligence (IJCAI)*, 729–735.\n\n2. Dalvi, N., Kumar, R., & Soliman, M. (2011). Automatic wrappers for large scale web extraction. *Proceedings of the VLDB Endowment*, 4(4), 219–230.\n\n3. Ferrara, E., De Meo, P., Fiumara, G., & Baumgartner, R. (2014). Web data extraction, applications and techniques: A survey. *Knowledge-Based Systems*, 70, 301–323.\n\n4. Kohlschütter, C., Fankhauser, P., & Nejdl, W. (2010). Boilerplate detection using shallow text features. *Proceedings of the Third ACM International Conference on Web Search and Data Mining (WSDM)*, 441–450.\n\n5. Lockard, C., Dong, X. L., Einolghozati, A., & Shiralkar, P. (2020). ZeroShotCeres: Zero-shot relation extraction from semi-structured webpages. *Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL)*, 8105–8117.\n\n6. Li, J., Xu, Y., Cui, L., & Wei, F. (2022). MarkupLM: Pre-training of text and markup language for visually rich document understanding. *Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (ACL)*, 6078–6087.\n\n7. Wang, X., Jiang, Y., Bach, N., Wang, T., Huang, Z., Huang, F., & Tu, K. (2022). WebFormer: The web-page transformer for structure information extraction. *Proceedings of the ACM Web Conference 2022*, 3124–3133.\n\n8. Deng, X., Sun, Y., Galley, M., & Gao, J. (2022). DOM-LM: Learning generalizable representations for HTML documents. *arXiv preprint arXiv:2201.10608*.\n\n9. Tong, M. (2014). Diffbot: A visual learning agent for the web. *Diffbot Technologies*. https://www.diffbot.com/\n\n10. Gur, I., Furuta, H., Huang, A., Saber, M., Matsuo, Y., Eck, D., & Faust, A. (2023). A real-world WebAgent with planning, long context understanding, and program synthesis. *arXiv preprint arXiv:2307.12856*.\n\n11. Perini, M., Samardzic, L., & Pozzoli, M. (2024). ScrapeGraphAI: A web scraping python library that uses LLM and direct graph logic to create scraping pipelines. *arXiv preprint arXiv:2411.13104*.\n\n12. FireCrawl. (2024). FireCrawl: Turn websites into LLM-ready data. https://firecrawl.dev/\n\n13. crawl4ai. (2024). crawl4ai: Open-source LLM-friendly web crawler. https://github.com/unclecode/crawl4ai\n\n14. Google. (2025). Gemini 2.5 Flash. *Google DeepMind*. https://deepmind.google/technologies/gemini/\n\n15. Clark, J., & DeRose, S. (1999). XML Path Language (XPath) Version 1.0. *W3C Recommendation*. https://www.w3.org/TR/xpath/\n\n16. XPath Agent. (2024). Multi-sample XPath generation via two-stage LLM pipeline. *arXiv preprint arXiv:2502.15688*.\n\n17. Huang, J., & Song, J. (2025). Automatic XPath generation agents for vertical websites by LLMs. *Journal of King Saud University — Computer and Information Sciences*.\n\n18. AXE: Adaptive X-Path Extractor. (2026). DOM pruning for efficient LLM-based XPath extraction with grounded resolution. *arXiv preprint arXiv:2602.01838*.\n\n19. Hao, Q., Cai, R., Pang, Y., & Zhang, L. (2011). From one tree to a forest: A unified solution for structured web data extraction. *Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval*, 775–784.\n\n---\n\n## Appendix A: LLM プロンプト\n\n以下は XPathGenie のパイプラインで使用される完全なプロンプトである。すべてのプロンプトは `generateContent` API を介して Gemini 2.5 Flash に `temperature=0.1` で送信される。\n\n### A.1 Auto Discover プロンプト（PROMPT_DISCOVER）\n\n```\nYou are an expert web scraper. Analyze the following compressed HTML samples from the same website.\nIdentify all meaningful data fields that can be extracted, and provide XPath expressions that work across all pages.\n\nRules:\n- Return ONLY a JSON object: {\"field_name\": \"xpath_expression\", ...}\n- Keep XPaths SHORT and SIMPLE. Avoid deeply nested conditions. Prefer: //dt[normalize-space()='ラベル']/following-sibling::dd[1]\n- Field names must be lowercase English, descriptive, generic (e.g. price, title, facility_name, prefecture, address, phone, description, salary, job_type, access, working_hours)\n- Limit to the 20 most important fields maximum\n- XPaths must use // prefix and select element nodes (not text() nodes)\n- For class matching, ALWAYS use contains() because classes often have multiple values (e.g. //div[contains(@class,'price')], NOT //div[@class='price'])\n- For text matching, ALWAYS use normalize-space() to handle whitespace: //dt[normalize-space()='ラベル'] or //td[normalize-space()='ラベル']\n- For dt/dd patterns, use: //dl[dt[normalize-space()='ラベル']]/dd or //dt[normalize-space()='ラベル']/following-sibling::dd[1]\n- Do NOT use XPath functions like substring-after. contains(@class,...) and normalize-space() are OK.\n- Include all extractable fields you can identify\n- Do NOT include navigation, header, footer, sidebar, or boilerplate fields\n- Output SIMPLE XPaths with NO container prefix (the system adds scoping automatically)\n- Example: //dt[normalize-space()='給与']/following-sibling::dd[1] (correct)\n- Example: //div[contains(@class,'xxx')]//dt[...] (WRONG — do not add container)\n- Return valid JSON only, no markdown, no explanation\n\nHTML samples:\n[compressed HTML inserted here]\n```\n\n### A.2 Want List プロンプト（PROMPT_WANTLIST）\n\n```\nYou are an expert web scraper. Analyze the following compressed HTML samples from the same website.\nThe user wants to extract SPECIFIC fields. Find the best XPath for each requested field.\n\nRequested fields (JSON schema):\n[user-provided want list inserted here]\n\nRules:\n- Return ONLY a JSON object with the EXACT same keys as the requested schema: {\"field_name\": \"xpath_expression\", ...}\n- You MUST include ALL requested field names in the output, even if you cannot find a match (use null for XPath in that case)\n- Keep XPaths SHORT and SIMPLE. Prefer: //dt[normalize-space()='ラベル']/following-sibling::dd[1]\n- XPaths must use // prefix and select element nodes (not text() nodes)\n- For class matching, ALWAYS use contains() because classes often have multiple values\n- For text matching, ALWAYS use normalize-space() to handle whitespace\n- For dt/dd patterns, use: //dl[dt[normalize-space()='ラベル']]/dd or //dt[normalize-space()='ラベル']/following-sibling::dd[1]\n- Do NOT use XPath functions like substring-after. contains(@class,...) and normalize-space() are OK.\n- Match fields by MEANING, not by label text (e.g. \"price\" matches \"給与\", \"時給\", \"報酬\", \"salary\")\n- The VALUES in the schema are hints/descriptions of what the user wants for that field\n- Output SIMPLE XPaths with NO container prefix (the system adds scoping automatically)\n- Return valid JSON only, no markdown, no explanation\n\nHTML samples:\n[compressed HTML inserted here]\n```\n\n### A.3 精緻化プロンプト（PROMPT_REFINE）\n\n```\nYou are an expert web scraper. Some XPath expressions matched MULTIPLE nodes on the same page.\nFor each field, examine the surrounding HTML context of the multiple matches, determine which match is the PRIMARY/most important one (the main job detail, not sidebar/recommendations/summary), and return a MORE SPECIFIC XPath that matches only that one.\n\nStrategy:\n- Look for intermediate structural containers (divs with meaningful class names) between the page-level container and the target dt/dd\n- Use these intermediate containers to narrow down to the correct section\n- For example: if both \"job detail\" and \"job summary\" sections have dt[normalize-space()='勤務地'], add the job-detail section's parent class\n- Pick the match that contains the MOST DETAILED information (full description > summary)\n- Keep XPaths as simple as possible while being unique\n\nFields that need refinement:\n[field context with match counts and HTML snippets inserted here]\n\nRules:\n- Return ONLY a JSON object: {\"field_name\": \"refined_xpath\", ...}\n- Include ONLY the fields listed above (the ones that need fixing)\n- XPaths must start with // and use contains(@class,...) for class matching\n- Do NOT use functions like substring-after or normalize-space\n- Return valid JSON only, no markdown, no explanation\n```\n\n## Appendix B: LLM 推論の実例\n\n以下に、Hacker News のディスカッションページ（https://news.ycombinator.com/item?id=1）を Auto Discover モードで分析した際の LLM の中間推論過程を示す。最終的な JSON 出力の前に明示的なステップバイステップの推論を要求するようプロンプトを修正して実施した。\n\n### B.1 ページ分析の推論過程\n\n> **1. これはどのような種類のページか？**\n> この HTML は Hacker News の「item」すなわち「story」ページを表している。`<html>` タグに `op=\"item\"` が付与されており、これは強力な手がかりとなる。\n>\n> **2. どのような HTML 構造パターンが見られるか？**\n> - **全体レイアウト:** ページコンテンツ全体が `id=\"hnmain\"` を持つ中央の `<table>` 内に格納されている。\n> - **ストーリー・投稿ブロック:** ストーリー自体は `class=\"fatitem\"` を持つ `<table>` 内に表示される。ストーリーの核となる情報は `class=\"athing submission\"` を持つ `<tr>` 内にある。\n>   - タイトルと URL は `span.titleline` 内にある。\n>   - スコア、著者、投稿日時、コメント数は `td.subtext` 内の `span.subline` にある。\n> - **コメントブロック:** `class=\"comment-tree\"` を持つ `<table>` がすべてのコメントを保持する。各コメントは `class=\"athing comtr\"` を持つ `<tr>` である。コメントは `class=\"ind\"` と `indent` 属性を持つ `<td>` 要素によりネストされている。\n>\n> **3. 利用可能なデータフィールドは何か？**\n> ストーリー詳細: タイトル、URL、ドメイン、スコア、著者、タイムスタンプ、コメント数。\n> コメント詳細: ID、著者、テキスト、タイムスタンプ、インデントレベル。\n>\n> **4. 各フィールドの XPath をどのように選択したか？**\n> ストーリーフィールドについては `fatitem` テーブル構造とその subtext span を対象とした。コメントについては `comtr` クラスの行を持つ `comment-tree` テーブルを対象とし、ネストの深さには `indent` 属性を利用した。\n\n### B.2 最終出力（14 フィールド）\n\n```json\n{\n  \"title\": \"//span[contains(@class,'titleline')]/a\",\n  \"url\": \"//span[contains(@class,'titleline')]/a/@href\",\n  \"domain\": \"//span[contains(@class,'sitebit')]//span[contains(@class,'sitestr')]\",\n  \"points\": \"//span[contains(@class,'score')]\",\n  \"author\": \"//a[contains(@class,'hnuser')]\",\n  \"posted_date\": \"//span[contains(@class,'age')]\",\n  \"posted_timestamp\": \"//span[contains(@class,'age')]/@title\",\n  \"comments_count\": \"//span[contains(@class,'subline')]/a[contains(@href,'item')]\",\n  \"comment_author\": \"//span[contains(@class,'comhead')]//a[contains(@class,'hnuser')]\",\n  \"comment_text\": \"//div[contains(@class,'commtext')]\",\n  \"comment_id\": \"//tr[contains(@class,'comtr')]/@id\",\n  \"comment_indent_level\": \"//td[contains(@class,'ind')]/@indent\",\n  \"comment_posted_date\": \"//span[contains(@class,'comhead')]//span[contains(@class,'age')]\",\n  \"comment_posted_timestamp\": \"//span[contains(@class,'comhead')]//span[contains(@class,'age')]/@title\"\n}\n```\n\nこの実例は、LLM が (1) HTML 属性からページ種別を正しく識別し、(2) ネストされたコメントツリーを含む構造パターンを認識し、(3) ナビゲーションやボイラープレートを除外しつつ関連するデータフィールドを特定し、(4) 各パターン種別に対して適切な XPath 戦略を選択していることを示している。\n\n### B.3 失敗事例: Goodreads（0% — React SSR）\n\n特定のサイトが失敗する理由を例示するため、0 フィールドを返した Goodreads（https://www.goodreads.com/book/show/11127）における LLM の推論を検証した。\n\n**圧縮後 HTML（278 文字 — 元の 740KB から）:**\n\n```html\n<html lang=\"en\"><body><div><!-- This is a random-length HTML comment:\nGG5q7MffqRiWLiIKn2Nl07ClU7nVXOa*D1ndg5L[8uE^h... --></div></body></html>\n```\n\n**LLM の推論:**\n\n> **1. これはどのような種類のページか？**\n> これは極めて最小限の、空の、またはプレースホルダーのページに見える。`div` 要素の唯一のコンテンツは長くランダムに見える HTML コメントである。これはコンテンツの読み込みに失敗したページ、もしくは JavaScript によりコンテンツが動的に注入される前の Web アプリケーションの初期状態である可能性がある。\n>\n> **3. 利用可能なデータフィールドは何か？**\n> 有用なデータフィールドはほぼ皆無である。唯一の明示的な情報は `lang=\"en\"` 属性のみである。\n>\n> **4. なぜ XPath 抽出が困難か？**\n> 主たる課題は実データの不在である。コンテンツはクライアントサイドで実行される JavaScript バンドル内にのみ存在し、サーバーレンダリングされた HTML 内には含まれない。\n\n**分析:** Goodreads はランダム化されたコメント（キャッシュバスティングトークンと推測される）を含む最小限の HTML シェルを配信し、すべての可視コンテンツをクライアントサイド JavaScript でレンダリングする。意味的 HTML では効果的に機能する 97% の圧縮率（Hacker News: 6.4KB → 278 バイトで全構造を保持）が、React SSR ページでは破壊的に作用する（740KB → 278 バイト、コンテンツの 100% が失われる）。これは XPathGenie の失敗モードが XPath 生成ではなく **HTML 取得レイヤ** にあることを確認するものである。サーバーレンダリングされた HTML にはブラウザ上でユーザーが目にするデータが単純に含まれていない。これは JavaScript を実行しないすべてのスクレイピングアプローチに共通する根本的な制約である。\n\n## Appendix C: 再現性メタデータ\n\n### C.1 評価環境\n\n| パラメータ | 値 |\n|---|---|\n| **LLM** | Gemini 2.5 Flash (google/gemini-2.5-flash) |\n| **Temperature** | 0.1 |\n| **レスポンス形式** | JSON (responseMimeType=application/json) |\n| **XPath エンジン** | lxml 5.x (Python) |\n| **圧縮上限** | 8,000 文字/ページ |\n| **評価実施時期** | 2026 年 2 月 |\n| **User-Agent** | Python urllib / requests (default) |\n\n### C.2 データの利用可能性\n\n| データセット | 所在 | 内容 |\n|---|---|---|\n| **主要評価**（日本語 23 サイト） | `docs/evaluation/results/` | サイトごとの JSON 結果ファイル（HTML スナップショットなし） |\n| **日本語クロスドメイン**（10 サイト） | `docs/evaluation/cross_domain_eval.py` | 評価スクリプト＋結果 |\n| **英語評価**（10 サイト） | `tests/e2e/snapshots/260218_en_v2/`, `260218_en_v3/` | アーカイブ済み HTML ページ（30 ファイル） |\n| **SWDE ベンチマーク**（22 サイト） | `data/swde/html/`, `data/swde/groundtruth/` | アーカイブ済み HTML ページ（220 ファイル）＋正解アノテーション |\n| **SWDE 評価スクリプト** | `docs/evaluation/swde_real_eval.py` | 完全再現可能な評価パイプライン |\n| **XPath マッピング** | `docs/evaluation/xpath_mappings.json` | 全生成 XPath 式 |\n\n### C.3 再現性に関する注記\n\n- 23 の日本語医療系サイトを対象とした主要評価では、評価時に HTML スナップショットをアーカイブ **していない**。本番 Web サイトは変化するため、これらの結果の正確な再現は不可能な場合がある。結果 JSON ファイルには生成された XPath と検証結果が保存されている。\n- 英語評価および SWDE 評価ではすべての HTML ページをアーカイブしており、正確な再現が可能である。\n- LLM の非決定性（`temperature=0.1` にもかかわらず）により、実行間で軽微な変動が生じうる。3 回実行の再現性調査（Section 4.10）ではこれを定量化しており、21 サイト中 8 サイトが実行間で標準偏差 0 を示し、全体の平均ヒット率は 83.1% であった。",
  "tags": "XPathGenie, Whitepaper (日本語), bon-soleil, product"
}